{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9ERgBpbcMmB"
      },
      "source": [
        "# HW1: Frame-Level Speech Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLkH6GMGcWcE"
      },
      "source": [
        "In this homework, you will be working with MFCC data consisting of 28 features at each time step/frame. Your model should be able to recognize the phoneme occured in that frame."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezY4enYT7evo"
      },
      "source": [
        "# Schedule:\n",
        "- Checkpoint Submission (DUE 23 January 2026 @ 11:59PM EST)\n",
        "- Final Submission (DUE 6 February 2026 @ 11:59PM EST | Slack Deadline is 13 February 2026 @ 11:59PM EST)\n",
        "- Code Submission (DUE 8 February 2026 @ 11:59PM EST OR Day-of Slack submission)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-6ndg_m7evp"
      },
      "source": [
        "## Requirement Acknowledgement\n",
        "Setting the below flag to True indicates full understanding and acceptance of the following:\n",
        "1. Slack days may ONLY be used on P2 FINAL (not checkpoint) submission. I.e. you may use slack days to submit final P2 kaggle scores (such as this one) later on the **SLACK KAGGLE COMPETITION** at the expense of your Slack days.\n",
        "2. The final autolab **code submission is due 48 hours after** the conclusion of the Kaggle Deadline (or, the same day as your final kaggle submission).\n",
        "3. We will require your kaggle username here, and then we will pull your official PRIVATE kaggle leaderboard score. This submission may result in slight variance in scores/code, but we will check for acceptable discrepancies. Any discrepancies related to modifying the submission code (at the bottom of the notebook) will result in an AIV.\n",
        "4. You are NOT allowed to use any code that will pre-load models (such as those from Hugging Face, etc.).\n",
        "   You MAY use models described by papers or articles, but you MUST implement them yourself through fundamental PyTorch operations (i.e. Linear, Conv2d, etc.).\n",
        "5. You are NOT allowed to use any external data/datasets at ANY point of this assignment.\n",
        "6. You may work with teammates to run ablations/experiments, BUT you must submit your OWN code and your OWN results.\n",
        "7. Failure to comply with the prior rules will be considered an Academic Integrity Violation (AIV).\n",
        "8. Late submissions MUST be submitted through the Slack Kaggle (see writeup for details). Any submissions made to the regular Kaggle after the original deadline will NOT be considered, no matter how many slack days remain for the student."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Dcb6jKbr7evq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ACKNOWLEDGED = True #TODO: Only set Acknowledged to True if you have read the above acknowlegements and agree to ALL of them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2vp3N7qr_5V"
      },
      "source": [
        "# Dataset Description\n",
        "\n",
        "Let's start by understanding the dataset for this homework.\n",
        "\n",
        "Our data consists of 3 folders (train-clean-100, dev-clean and test-clean). The training and validation datasets (train-clean-100 and dev-clean) each contain 2 subfolders (mfcc and transcript). The 'mfcc' subfolder contains mel spectrograms (explained below and in writeup), while the 'transcript' subfolder contains their corresponding transcripts. However, the test dataset (test-clean) contains only the 'mfcc' subfolder without the corresponding transcripts, which will later be predicted by your model.\n",
        "\n",
        "\n",
        "## 1. Audio Representation.\n",
        "The 'mfcc' subfolders contain many `*.npy` files of mel spectrograms. .npy files are used to store numpy arrays.\n",
        "\n",
        "Each .npy file represents a short speech recording. For example, one recording might be someone saying, \"This is the age of AI.\" This recording is converted into a mel spectrogram, which is used to represent all forms of audio signals in a computer. Such representation is important in signal and speech processing tasks, especially in machine learning.\n",
        "\n",
        "Compared to raw audio, mel spectrograms are better for speech processing because they capture both the timing and the frequencies of the sound. At each moment in time, they show which frequencies are present in the sound. This makes it easier for computers to understand and process speech.\n",
        "\n",
        "When converting raw audio to spectrograms, you do not process the whole audio at once. Instead, you process small frames at a time as you stride over the entire audio length. This means that if you have an audio file of 100 seconds, you may decide to process 10 seconds at a time, striding by one second. In this case, the frame size is 10 seconds. The frame size and the number of timesteps (seconds, milliseconds, etc.) depend on individual choice.\n",
        "\n",
        "When processing each frame, you extract a number of features that represent that frame's audio. For instance, in the audio recording of \"This is the age of AI,\" the frame corresponding to \"AI\" will have features that represent how \"AI\" is pronounced, the vocal tract, and the effect of the environment in which it was recorded. For clarity, when we say features, you should think of columns. One feature/column may have information about the gender of the person who made the speech. Another may have information about the age of the person. Another may have information about the environment where the speech was recorded. Basically, the main properties that make up a speech are encoded in those features, which combine in some way to make the audio.\n",
        "\n",
        "Since we want to recognize the word as it was pronounced despite the environment and other variabilities, we usually normalize to eliminate or minimize such effects.\n",
        "\n",
        "Our spectrograms contain 28 features. Essentially, the number of features may be different. They may depend on how the raw audio data was converted into mel spectrograms.\n",
        "\n",
        "## 2. Transcripts\n",
        "Remember where we mentioned frames? Well, in our dataset, audio frames have corresponding target transcripts. For instance the abbreviation \"AI\", in our example above, if present in the recordings, will have transcripts: /eɪ aɪ/. This means that you will have two frames one for  /eɪ/ and another for /aɪ/.\n",
        "\n",
        "This way of representing pronounciation in text form is called ***phonetic transcription***, \"the conversion of spoken words the way they are pronounced instead of how they are written\"[[link]](https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://krisp.ai/blog/phonetic-transcription/%23:~:text%3Dphonetic%2520transcriptions%2520done.-,What%2520are%2520Phonetic%2520Transcriptions%253F,verbatim%2520to%2520intelligent%2520verbatim%2520transcriptions.&ved=2ahUKEwiV6LO6hrSHAxUKSvEDHcvwAAsQFnoECB0QAw&usg=AOvVaw0VqoWceOzdVwe-AvdyyWqJ). In this case letters 'A' and 'I' are pronounce /eɪ/ and /aɪ/, respectively. Both letters in different words may be pronounced differently.\n",
        "\n",
        "The produced representation of the speech is referred to as phonemes. Various .npy files that contain recordings of the sentence **\"This is the age of AI.\"** would map to **\"/ðɪs ɪz ðə eɪdʒ əv eɪ aɪ/.\"** The phonemes representation for **Chelsea sucks** would be **/ˈtʃɛl.si sʌks/**\n",
        "\n",
        "Going inside the .npy files. Each .npy file contains vectors which have 28 features/dimensions/columns. The number of vectors in the file corresponds to the number of frames in the recording. And each single frame has a corresponding phoneme in the transcript.\n",
        "\n",
        "For instance the .npy file for \"This is the age of AI\" --> \"/ðɪs ɪz ðə eɪdʒ əv eɪ aɪ/\" might have 13 frames (13 vectors):\n",
        "\n",
        "- /ðɪs/ has 3 phonemes: /ð/, /ɪ/, /s/  \n",
        "- /ɪz/ has 2 phonemes: /ɪ/, /z/\n",
        "- /ðə/ has 2 phonemes: /ð/, /ə/\n",
        "- /eɪdʒ/ has 2 phonemes: /eɪ/, /dʒ/\n",
        "- /əv/ has 2 phonemes: /ə/, /v/\n",
        "- /eɪ aɪ/ has 2 phonemes: /eɪ/, /aɪ/\n",
        "\n",
        "**Chelsea sucks** --> **/ˈtʃɛl.si sʌks/** might have 8 frames (8 vectors):\n",
        "\n",
        "- /ˈtʃɛl.si/ has 4 phonemes: /tʃ/, /ɛ/, /l/, /si/\n",
        "- /sʌks/ has 4 phonemes: /s/, /ʌ/, /k/, /s/\n",
        "\n",
        "Note that recordings of different sentences may have different number of frames.\n",
        "\n",
        "The model you will produce must take a vector of a particular frame and predict the frame's transcript as accurately as possible.\n",
        "\n",
        "Therefore, the **__getitem__** method of your dataset class must return a 28 dimensional vector of a particular frame and its corresponding phoneme transcript.\n",
        "\n",
        "This means that, while you are doing your data preprocessing in the **__init__** method, you need stack all vectors from all recordings on top of each other. You must do this for all transcripts as well and remember to ensure the correspondance between frames and their phoneme mapping is maintained.\n",
        "\n",
        "For our dataset of two samples above, if you stack the recordings together, you get:\n",
        "\n",
        "\n",
        "| Frame | Feature 1 | Feature 2 | ... | Feature 28 | Phoneme |\n",
        "|-------|-----------|-----------|-----|------------|---------|\n",
        "| 0     | v0_1      | v0_2      | ... | v0_28      | /ð/     |\n",
        "| 1     | v1_1      | v1_2      | ... | v1_28      | /ɪ/     |\n",
        "| 2     | v2_1      | v2_2      | ... | v2_28      | /s/     |\n",
        "| 3     | v3_1      | v3_2      | ... | v3_28      | /ɪ/     |\n",
        "| 4     | v4_1      | v4_2      | ... | v4_28      | /z/     |\n",
        "| 5     | v5_1      | v5_2      | ... | v5_28      | /ð/     |\n",
        "| 6     | v6_1      | v6_2      | ... | v6_28      | /ə/     |\n",
        "| 7     | v7_1      | v7_2      | ... | v7_28      | /eɪ/    |\n",
        "| 8     | v8_1      | v8_2      | ... | v8_28      | /dʒ/    |\n",
        "| 9     | v9_1      | v9_2      | ... | v9_28      | /ə/     |\n",
        "| 10    | v10_1     | v10_2     | ... | v10_28     | /v/     |\n",
        "| 11    | v11_1     | v11_2     | ... | v11_28     | /eɪ/    |\n",
        "| 12    | v12_1     | v12_2     | ... | v12_28     | /aɪ/    |\n",
        "| 13    | v13_1     | v13_2     | ... | v13_28     | /tʃ/    |\n",
        "| 14    | v14_1     | v14_2     | ... | v14_28     | /ɛ/     |\n",
        "| 15    | v15_1     | v15_2     | ... | v15_28     | /l/     |\n",
        "| 16    | v16_1     | v16_2     | ... | v16_28     | /si/     |\n",
        "| 17    | v17_1     | v17_2     | ... | v17_28     | /s/     |\n",
        "| 18    | v18_1     | v18_2     | ... | v18_28     | /ʌ/     |\n",
        "| 19    | v19_1     | v19_2     | ... | v19_28     | /k/     |\n",
        "| 20    | v20_1     | v20_2     | ... | v20_28     | /s/     |\n",
        "\n",
        "\n",
        "So, if you pass index 5 to **__getitem__**, you will get back vector v5 (v5_1, v5_2, ..., v5_28) and transcript **/ð/**. Ideally, if you have a well trained model, it should take v5 and return **/ð/**. And the call to **__len__** would return 21 which the training loop would use to go through the whole dataset.\n",
        "\n",
        "## Context\n",
        "\n",
        "In the dataset we are using, a few millisecs were used to convert raw audio to mel spectrogram and extract the 28 features.\n",
        "Since each vector represents only a few millisecs of speech, it may not be sufficient to feed only a single vector into the network at a time. Instead, it may be useful to provide the network with some “context” of size K around each vector in terms of additional vectors from the speech input.\n",
        "\n",
        "Concretely, a context of size 3 would mean that we provide an input of size (7, 28) to the network - the size 7 can be explained as: the vector to predict the label for, 3 vectors preceding this vector, and 3 vectors following it. It is worth thinking about how you would handle providing context before one of the first K frames of an utterance or after one of the last K frames.\n",
        "\n",
        "There are several ways to implement this, but you could try the simplest one:\n",
        "- Concatenating all utterances and padding with K 0-valued vectors before and after the resulting matrix\n",
        "\n",
        "If you use a context of 3 on the above table, you get the following table:\n",
        "\n",
        "| Frame | Feature 1 | Feature 2 | ... | Feature 28 | Phoneme | Context Vectors |\n",
        "|-------|-----------|-----------|-----|------------|---------|----------------|\n",
        "| 0     | v0_1      | v0_2      | ... | v0_28      | /ð/     | [0, 0, 0, ..., 0] (Padding), [0, 0, 0, ..., 0] (Padding), [0, 0, 0, ..., 0] (Padding), v0, v1, v2, v3 |\n",
        "| 1     | v1_1      | v1_2      | ... | v1_28      | /ɪ/     | [0, 0, 0, ..., 0] (Padding), [0, 0, 0, ..., 0] (Padding), v0, v1, v2, v3, v4 |\n",
        "| 2     | v2_1      | v2_2      | ... | v2_28      | /s/     | [0, 0, 0, ..., 0] (Padding), v0, v1, v2, v3, v4, v5 |\n",
        "| 3     | v3_1      | v3_2      | ... | v3_28      | /ɪ/     | v0, v1, v2, v3, v4, v5, v6 |\n",
        "| 4     | v4_1      | v4_2      | ... | v4_28      | /z/     | v1, v2, v3, v4, v5, v6, v7 |\n",
        "| 5     | v5_1      | v5_2      | ... | v5_28      | /ð/     | v2, v3, v4, v5, v6, v7, v8 |\n",
        "| 6     | v6_1      | v6_2      | ... | v6_28      | /ə/     | v3, v4, v5, v6, v7, v8, v9 |\n",
        "| 7     | v7_1      | v7_2      | ... | v7_28      | /eɪ/    | v4, v5, v6, v7, v8, v9, v10 |\n",
        "| 8     | v8_1      | v8_2      | ... | v8_28      | /dʒ/    | v5, v6, v7, v8, v9, v10, v11 |\n",
        "| 9     | v9_1      | v9_2      | ... | v9_28      | /ə/     | v6, v7, v8, v9, v10, v11, v12 |\n",
        "| 10    | v10_1     | v10_2     | ... | v10_28     | /v/     | v7, v8, v9, v10, v11, v12, v13 |\n",
        "| 11    | v11_1     | v11_2     | ... | v11_28     | /eɪ/    | v8, v9, v10, v11, v12, v13, v14 |\n",
        "| 12    | v12_1     | v12_2     | ... | v12_28     | /aɪ/    | v9, v10, v11, v12, v13, v14, v15 |\n",
        "| 13    | v13_1     | v13_2     | ... | v13_28     | /tʃ/    | v10, v11, v12, v13, v14, v15, v16 |\n",
        "| 14    | v14_1     | v14_2     | ... | v14_28     | /ɛ/     | v11, v12, v13, v14, v15, v16, v17 |\n",
        "| 15    | v15_1     | v15_2     | ... | v15_28     | /l/     | v12, v13, v14, v15, v16, v17, v18 |\n",
        "| 16    | v16_1     | v16_2     | ... | v16_28     | /s/     | v13, v14, v15, v16, v17, v18, v19 |\n",
        "| 17    | v17_1     | v17_2     | ... | v17_28     | /i/     | v14, v15, v16, v17, v18, v19, v20 |\n",
        "| 18    | v18_1     | v18_2     | ... | v18_28     | /s/     | v15, v16, v17, v18, v19, v20, v21 |\n",
        "| 19    | v19_1     | v19_2     | ... | v19_28     | /ʌ/     | v16, v17, v18, v19, v20, v21, [0, 0, 0, ..., 0] (Padding) |\n",
        "| 20    | v20_1     | v20_2     | ... | v20_28     | /k/     | v17, v18, v19, v20, v21, [0, 0, 0, ..., 0] (Padding), [0, 0, 0, ..., 0] (Padding) |\n",
        "| 21    | v21_1     | v21_2     | ... | v21_28     | /s/     | v18, v19, v20, v21, [0, 0, 0, ..., 0] (Padding), [0, 0, 0, ..., 0] (Padding), [0, 0, 0, ..., 0] (Padding) |\n",
        "\n",
        "\n",
        "Now, if you want to predict the output of vector v5, you won't just pass vector v5 alone. You will concatenate 3 vectors before it and 3 vectors after, which makes it 7 vectors ([v2, v3, v4, v5, v6, v7, v8 ]) . This needs to be reflected in your **__getitem__** method. Meaning it should return an array of shape (7, 28), in this example.\n",
        "\n",
        "Hence your model is going to be taking a tensor (array) of shape (7, 28) in this example."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vZbDmJvMp1"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:17:06.712521Z",
          "iopub.status.busy": "2024-12-31T15:17:06.712105Z",
          "iopub.status.idle": "2024-12-31T15:17:11.315040Z",
          "shell.execute_reply": "2024-12-31T15:17:11.313841Z",
          "shell.execute_reply.started": "2024-12-31T15:17:06.712491Z"
        },
        "id": "rwYu9sSUnSho",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install wandb --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:17:11.316919Z",
          "iopub.status.busy": "2024-12-31T15:17:11.316603Z",
          "iopub.status.idle": "2024-12-31T15:17:14.498760Z",
          "shell.execute_reply": "2024-12-31T15:17:14.497781Z",
          "shell.execute_reply.started": "2024-12-31T15:17:11.316883Z"
        },
        "id": "ijYNIOkpYrXf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "!pip install torchaudio --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:17:14.500390Z",
          "iopub.status.busy": "2024-12-31T15:17:14.500076Z",
          "iopub.status.idle": "2024-12-31T15:17:20.483241Z",
          "shell.execute_reply": "2024-12-31T15:17:20.482519Z",
          "shell.execute_reply.started": "2024-12-31T15:17:14.500361Z"
        },
        "id": "qI4qfx7tiBZt",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import gc\n",
        "import zipfile\n",
        "import bisect\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "import os\n",
        "import datetime\n",
        "import wandb\n",
        "import yaml\n",
        "import torchaudio.transforms as tat\n",
        "import torchaudio\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "use_bf16 = (device==\"cuda\") and torch.cuda.is_bf16_supported()\n",
        "amp_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "scaler = torch.amp.GradScaler('cuda', not use_bf16)\n",
        "print(\"Device: \", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqsFLqa6rCuc"
      },
      "source": [
        "# Mount Google Drive (Colab Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Z23Nag1jq_yA"
      },
      "outputs": [],
      "source": [
        "''' If you are using colab, you can import google drive to save model checkpoints in a folder\n",
        "    If you are NOT running on Colab, skip this cell\n",
        "'''\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:17:20.484621Z",
          "iopub.status.busy": "2024-12-31T15:17:20.484276Z",
          "iopub.status.idle": "2024-12-31T15:17:20.489243Z",
          "shell.execute_reply": "2024-12-31T15:17:20.488394Z",
          "shell.execute_reply.started": "2024-12-31T15:17:20.484588Z"
        },
        "id": "N-9qE20hmCgQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "### PHONEME LIST\n",
        "PHONEMES = [\n",
        "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',\n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIi0Big7vPa9"
      },
      "source": [
        "# Kaggle API Setup (Colab/AWS Only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBCbeRhixGM7"
      },
      "source": [
        "This section contains code that helps you install kaggle's API, creating kaggle.json with you username and API key details. Make sure to input those in the given code to ensure you can download data from the competition successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T01:51:36.557771Z",
          "iopub.status.busy": "2024-12-24T01:51:36.557557Z",
          "iopub.status.idle": "2024-12-24T01:51:39.853407Z",
          "shell.execute_reply": "2024-12-24T01:51:39.852241Z",
          "shell.execute_reply.started": "2024-12-24T01:51:36.557752Z"
        },
        "id": "TPBUd7Cnl-Rx",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (1.7.4.5)\n",
            "Requirement already satisfied: bleach in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (6.3.0)\n",
            "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (2026.1.4)\n",
            "Requirement already satisfied: charset-normalizer in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (3.4.4)\n",
            "Requirement already satisfied: idna in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (3.11)\n",
            "Requirement already satisfied: protobuf in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (6.33.4)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (2.9.0.post0)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: requests in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (2.32.5)\n",
            "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (80.9.0)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (1.17.0)\n",
            "Requirement already satisfied: text-unidecode in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (1.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (4.67.1)\n",
            "Requirement already satisfied: urllib3>=1.15.1 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (2.6.3)\n",
            "Requirement already satisfied: webencodings in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle) (0.5.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The syntax of the command is incorrect.\n",
            "'chmod' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "''' If you are running on Kaggle, skip this cell\n",
        "'''\n",
        "\n",
        "if \"KAGGLE_KERNEL_RUN_TYPE\" not in os.environ:\n",
        "    !pip install --upgrade kaggle\n",
        "    !mkdir /root/.kaggle\n",
        "\n",
        "    with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
        "        # TODO: Put your kaggle username & key here\n",
        "        f.write('{\"username\":\"YOUR_USERNAME\",\"key\":\"YOUR_KEY\"}')\n",
        "\n",
        "    !chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTs0uaLU7evw"
      },
      "source": [
        "# Kaggle Credentials & Client Setup (Kaggle Only)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0WbCmoGI7evw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "''' If you NOT running on Kaggle, skip this cell\n",
        "'''\n",
        "\n",
        "if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
        "  # IMPORTANT: Set kaggle Constants & environment variables for API Usage\n",
        "  KAGGLE_USERNAME = \"xulunluo\"\n",
        "  KAGGLE_API_KEY = \"2ce2c6e3c579210234c0853bb184a9fe\"\n",
        "\n",
        "  # Set in env for kaggle client\n",
        "  import os\n",
        "  os.environ[\"KAGGLE_USERNAME\"] = KAGGLE_USERNAME\n",
        "  os.environ[\"KAGGLE_KEY\"] = KAGGLE_API_KEY\n",
        "  print(\"Kaggle credentials set.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npqu-ZG47evw"
      },
      "source": [
        "# Download Dataset (Colab/AWS Only)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVOSKn0AdltM"
      },
      "source": [
        "If working on Kaggle, please add the competition as an input (go to add input, filter by Your Work and Competitions, and add the S26 HW1P2 Competition by clicking the + button). The competition already has the dataset, so you can use that as your \"ROOT\" directory! For other platforms, you will have to download the data and mount it locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T01:51:39.854726Z",
          "iopub.status.busy": "2024-12-24T01:51:39.854463Z",
          "iopub.status.idle": "2024-12-24T01:52:39.968030Z",
          "shell.execute_reply": "2024-12-24T01:52:39.967153Z",
          "shell.execute_reply.started": "2024-12-24T01:51:39.854703Z"
        },
        "id": "if2Somqfbje1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaggle==1.6.14\n",
            "  Using cached kaggle-1.6.14-py3-none-any.whl\n",
            "Requirement already satisfied: kagglesdk==0.1.13 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (0.1.13)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (1.17.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (2026.1.4)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (2.9.0.post0)\n",
            "Requirement already satisfied: requests in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (2.32.5)\n",
            "Requirement already satisfied: tqdm in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (4.67.1)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (2.6.3)\n",
            "Requirement already satisfied: bleach in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kaggle==1.6.14) (6.3.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from kagglesdk==0.1.13) (6.33.4)\n",
            "Requirement already satisfied: webencodings in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from bleach->kaggle==1.6.14) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from python-slugify->kaggle==1.6.14) (1.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from requests->kaggle==1.6.14) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from requests->kaggle==1.6.14) (3.11)\n",
            "Requirement already satisfied: colorama in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (from tqdm->kaggle==1.6.14) (0.4.6)\n",
            "Installing collected packages: kaggle\n",
            "  Attempting uninstall: kaggle\n",
            "    Found existing installation: kaggle 1.7.4.5\n",
            "    Uninstalling kaggle-1.7.4.5:\n",
            "      Successfully uninstalled kaggle-1.7.4.5\n",
            "Successfully installed kaggle-1.6.14\n",
            "hw-1-p-2-spring-2026-student-competition.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'unzip' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle==1.6.14 kagglesdk==0.1.13\n",
        "\n",
        "''' If running on Kaggle, skip this cell\n",
        "'''\n",
        "\n",
        "if \"KAGGLE_KERNEL_RUN_TYPE\" not in os.environ:\n",
        "    # commands to download data from kaggle\n",
        "    !kaggle competitions download -c hw-1-p-2-spring-2026-student-competition\n",
        "\n",
        "    # Unzip downloaded data\n",
        "    !unzip -qo /content/hw-1-p-2-spring-2026-student-competition.zip -d '/content/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNacQ8bpt9nw"
      },
      "source": [
        "# Parameters Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WE7tsinAuLNy"
      },
      "source": [
        "Storing your parameters and hyperparameters in a single configuration dictionary makes it easier to keep track of them during each experiment. It can also be used with weights and biases to log your parameters for each experiment and keep track of them across multiple experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "config = {\n",
        "    'Name': 'Xulun Luo', # Write your name here\n",
        "    'subset': 1.0, # Subset of train/val dataset to use (1.0 == 100% of data)\n",
        "    'context': 40,\n",
        "    'archetype': 'diamond', # Default Values: pyramid, diamond, inverse-pyramid,cylinder\n",
        "    'activations': 'GELU',\n",
        "    'learning_rate': 0.001,\n",
        "    'dropout': 0.1,\n",
        "    'optimizers': 'AdamW',\n",
        "    'scheduler': 'OneCycleLR',\n",
        "    'epochs': 45,\n",
        "    'batch_size': 1024,\n",
        "    'weight_decay': 0.001,\n",
        "    'weight_initialization': 'xavier_normal', # e.g kaiming_normal, kaiming_uniform, uniform, xavier_normal or xavier_uniform\n",
        "    'augmentations': 'Both', # Options: [\"FreqMask\", \"TimeMask\", \"Both\", null]\n",
        "    'freq_mask_param': 6,\n",
        "    'time_mask_param': 20\n",
        " }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "vzeqgWS9pumb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Name': 'Xulun Luo',\n",
              " 'subset': 1.0,\n",
              " 'context': 40,\n",
              " 'archetype': 'diamond',\n",
              " 'activations': 'GELU',\n",
              " 'learning_rate': 0.001,\n",
              " 'dropout': 0.1,\n",
              " 'optimizers': 'AdamW',\n",
              " 'scheduler': 'OneCycleLR',\n",
              " 'epochs': 45,\n",
              " 'batch_size': 1024,\n",
              " 'weight_decay': 0.001,\n",
              " 'weight_initialization': 'xavier_normal',\n",
              " 'augmentations': 'Both',\n",
              " 'freq_mask_param': 6,\n",
              " 'time_mask_param': 20}"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYeyFHQ1yRi4"
      },
      "source": [
        "# Dataset Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_7QgMbBdgPp"
      },
      "source": [
        "This section covers the dataset/dataloader class for speech data. You will have to spend time writing code to create this class successfully. We have given you a lot of comments guiding you on what code to write at each stage, from top to bottom of the class. Please try and take your time figuring this out, as it will immensely help in creating dataset/dataloader classes for future homeworks.\n",
        "\n",
        "Before running the following cells, please take some time to analyse the structure of data. Try loading a single MFCC and its transcipt, print out the shapes and print out the values. Do the transcripts look like phonemes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:17:54.383981Z",
          "iopub.status.busy": "2024-12-31T15:17:54.383641Z",
          "iopub.status.idle": "2024-12-31T15:17:54.394276Z",
          "shell.execute_reply": "2024-12-31T15:17:54.393413Z",
          "shell.execute_reply.started": "2024-12-31T15:17:54.383952Z"
        },
        "id": "HYU4NAH65dSb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset class to load train and validation data\n",
        "\n",
        "class AudioDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, root, phonemes = PHONEMES, context=0, partition= \"train-clean-100\"): # Feel free to add more arguments\n",
        "\n",
        "        self.context    = context\n",
        "        self.phonemes   = phonemes\n",
        "        self.subset = config['subset']\n",
        "\n",
        "        # TODO: Initialize augmentations. Read the Pytorch torchaudio documentations on timemasking and frequencymasking\n",
        "        self.freq_masking = tat.FrequencyMasking(freq_mask_param = config['freq_mask_param'])\n",
        "        self.time_masking = tat.TimeMasking(time_mask_param = config['time_mask_param'])\n",
        "\n",
        "\n",
        "        # TODO: MFCC directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        self.mfcc_dir       = os.path.join(root, partition, \"mfcc\")\n",
        "        # TODO: Transcripts directory - use partition to acces train/dev directories from kaggle data using root\n",
        "        self.transcript_dir = os.path.join(root, partition, \"transcript\")\n",
        "\n",
        "        # TODO: List files in sefl.mfcc_dir using os.listdir in SORTED order\n",
        "        mfcc_names          = sorted(os.listdir(self.mfcc_dir))\n",
        "        # TODO: List files in self.transcript_dir using os.listdir in SORTED order\n",
        "        transcript_names    = sorted(os.listdir(self.transcript_dir))\n",
        "\n",
        "        # Compute size of data subset\n",
        "        subset_size = int(self.subset * len(mfcc_names))\n",
        "\n",
        "        # Select subset of data to use\n",
        "        mfcc_names = mfcc_names[:subset_size]\n",
        "        transcript_names = transcript_names[:subset_size]\n",
        "\n",
        "        # Making sure that we have the same no. of mfcc and transcripts\n",
        "        assert len(mfcc_names) == len(transcript_names)\n",
        "\n",
        "        self.mfccs, self.transcripts = [], []\n",
        "\n",
        "\n",
        "        # TODO: Iterate through mfccs and transcripts\n",
        "        for i in tqdm(range(len(mfcc_names))):\n",
        "\n",
        "            # TODO: Load a single mfcc. Hint: Use numpy\n",
        "            mfcc             = np.load(os.path.join(self.mfcc_dir, mfcc_names[i]))\n",
        "            # TODO: Do Cepstral Normalization of mfcc along the Time Dimension (Think about the correct axis)\n",
        "            mfccs_normalized = (mfcc - mfcc.mean(axis=0)) / (mfcc.std(axis=0) + 1e-8)\n",
        "\n",
        "            # Convert mfcc to tensor\n",
        "            mfccs_normalized = torch.tensor(mfccs_normalized, dtype=torch.float32)\n",
        "\n",
        "            # TODO: Load the corresponding transcript\n",
        "            # Remove [SOS] and [EOS] from the transcript\n",
        "            # (Is there an efficient way to do this without traversing through the transcript?)\n",
        "            # Note that SOS will always be in the starting and EOS at end, as the name suggests.\n",
        "            transcript = np.load(os.path.join(self.transcript_dir, transcript_names[i]), allow_pickle = True)\n",
        "            transcript = transcript[1:-1] # Remove [SOS] and [EOS] from the transcript\n",
        "\n",
        "            # The available phonemes in the transcript are of string data type\n",
        "            # But the neural network cannot predict strings as such.\n",
        "            # Hence, we map these phonemes to integers\n",
        "\n",
        "            # TODO: Map the phonemes to their corresponding list indexes in self.phonemes\n",
        "            transcript_indices = [self.phonemes.index(p) for p in transcript]\n",
        "            # Now, if an element in the transcript is 0, it means that it is 'SIL' (as per the above example)\n",
        "\n",
        "            # Convert transcript to tensor\n",
        "            transcript_indices = torch.tensor(transcript_indices, dtype=torch.int64)\n",
        "\n",
        "            # Append each mfcc to self.mfcc, transcript to self.transcript\n",
        "            self.mfccs.append(mfccs_normalized)\n",
        "            self.transcripts.append(transcript_indices)\n",
        "\n",
        "        # NOTE:\n",
        "        # Each mfcc is of shape T1 x 28, T2 x 28, ...\n",
        "        # Each transcript is of shape (T1+2), (T2+2) before removing [SOS] and [EOS]\n",
        "\n",
        "        # TODO: Concatenate all mfccs in self.mfccs such that\n",
        "        # the final shape is T x 28 (Where T = T1 + T2 + ...)\n",
        "        # Hint: Use torch to concatenate\n",
        "        self.mfccs          = torch.cat(self.mfccs, dim = 0)\n",
        "\n",
        "        # TODO: Concatenate all transcripts in self.transcripts such that\n",
        "        # the final shape is (T,) meaning, each time step has one phoneme output\n",
        "        # Hint: Use torch to concatenate\n",
        "        self.transcripts    = torch.cat(self.transcripts, dim = 0)\n",
        "\n",
        "        # Length of the dataset is now the length of concatenated mfccs/transcripts\n",
        "        self.length = len(self.mfccs)\n",
        "\n",
        "        # Take some time to think about what we have done.\n",
        "        # self.mfcc is an array of the format (Frames x Features).\n",
        "        # Our goal is to recognize phonemes of each frame\n",
        "\n",
        "        # We can introduce context by padding zeros on top and bottom of self.mfcc\n",
        "        # Hint: Use torch.nn.functional.pad\n",
        "        # torch.nn.functional.pad takes the padding in the form of (left, right, top, bottom) for 2D data\n",
        "        self.mfccs = torch.nn.functional.pad(self.mfccs, (0, 0, self.context, self.context)) # TODO\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "      x, y = zip(*batch)\n",
        "      x = torch.stack(x, dim=0)\n",
        "\n",
        "      # Apply augmentations with 70% probability (You can modify the probability)\n",
        "      if np.random.rand() < 0.8:\n",
        "        x = x.transpose(1, 2)  # Shape: (batch_size, freq, time)\n",
        "        x = self.freq_masking(x)\n",
        "        x = self.time_masking(x)\n",
        "        x = x.transpose(1, 2)  # Shape back to: (batch_size, time, freq)\n",
        "\n",
        "      return x, torch.tensor(y)\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        # TODO: Based on context and offset, return a frame at given index with context frames to the left, and right.\n",
        "        frames = self.mfccs[ind : ind + 2*self.context + 1]\n",
        "\n",
        "        # After slicing, you get an array of shape 2*context+1 x 28.\n",
        "\n",
        "        phonemes = self.transcripts[ind]\n",
        "\n",
        "        return frames, phonemes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:18:40.554498Z",
          "iopub.status.busy": "2024-12-31T15:18:40.554136Z",
          "iopub.status.idle": "2024-12-31T15:18:40.561523Z",
          "shell.execute_reply": "2024-12-31T15:18:40.560566Z",
          "shell.execute_reply.started": "2024-12-31T15:18:40.554472Z"
        },
        "id": "C0rme6iT5dSb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset class to load test data\n",
        "\n",
        "class AudioTestDataset(torch.utils.data.Dataset):\n",
        "   \n",
        "   def __init__(self, root, phonemes = PHONEMES, context = 0):\n",
        "      self.context = context\n",
        "      self.phonemes = phonemes\n",
        "\n",
        "      # Set up the path to test MFCC files\n",
        "      self.mfcc_dir = os.path.join(root, \"test-clean\", \"mfcc\")\n",
        "\n",
        "      # List all files in sorted order\n",
        "      mfcc_names = sorted(os.listdir(self.mfcc_dir))\n",
        "\n",
        "      # Load and normalize all MFCC files\n",
        "      self.mfccs = []\n",
        "\n",
        "      print(\"Loading test data...\")\n",
        "      for filename in tqdm(mfcc_names):\n",
        "         # Load the .npy file\n",
        "         mfcc = np.load(os.path.join(self.mfcc_dir, filename))\n",
        "         \n",
        "         # Cepstral normalization: mean=0, std=1 for each feature\n",
        "         # axis=0 means normalize along time dimension (each column separately)\n",
        "         mfcc_normalized = (mfcc - mfcc.mean(axis=0)) / (mfcc.std(axis=0) + 1e-8)\n",
        "         \n",
        "         # Convert to PyTorch tensor\n",
        "         mfcc_normalized = torch.tensor(mfcc_normalized, dtype=torch.float32)\n",
        "         \n",
        "         # Add to our list\n",
        "         self.mfccs.append(mfcc_normalized)\n",
        "      \n",
        "      # Concatenate all recordings into one big tensor\n",
        "      self.mfccs = torch.cat(self.mfccs, dim = 0)\n",
        "      self.length = len(self.mfccs)\n",
        "\n",
        "      # Pad with zeros for context\n",
        "      self.mfccs = torch.nn.functional.pad(self.mfccs, (0, 0, self.context, self.context))\n",
        "\n",
        "      print(f\"Loaded {self.length} test frames\")\n",
        "\n",
        "   def __len__(self):\n",
        "      return self.length\n",
        "\n",
        "   def __getitem__(self, ind):\n",
        "        frames = self.mfccs[ind : ind + 2 * self.context + 1]\n",
        "        return frames\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mlwaKlDt_2c"
      },
      "source": [
        "# Create Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAq5svwwYvHM"
      },
      "source": [
        "Notes:\n",
        "\n",
        "- You will need to set the root path which depends on your setup. For eg. if you are following out setup instruction:\n",
        "  - `Colab:` `\"/content/data/archive/11785-spring-2026-hw1p2\"`\n",
        "  - `Kaggle:` `\"/kaggle/input/hw-1-p-2-spring-2026-student-competition/archive/11785-spring-2026-hw1p2\"`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:19:09.189955Z",
          "iopub.status.busy": "2024-12-31T15:19:09.189592Z",
          "iopub.status.idle": "2024-12-31T15:24:30.163981Z",
          "shell.execute_reply": "2024-12-31T15:24:30.163061Z",
          "shell.execute_reply.started": "2024-12-31T15:19:09.189927Z"
        },
        "id": "gJvMzHhB5dSc",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "932c2febd9f347ae8c25696cb74e29d9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/28539 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1293c4fc95f44c94ba170058e4951351",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2703 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading test data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dbf6b972049740388c1256b7bc3bb871",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2620 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1934138 test frames\n"
          ]
        }
      ],
      "source": [
        "ROOT = r\"C:\\Users\\xulunl\\Desktop\\Intro to DeepLearning\\HW1\\HW1P2\\hw1p2_data\\archive\\11785-spring-2026-hw1p2\" # Define the root directory of the dataset here\n",
        "\n",
        "# TODO: Create a dataset object using the AudioDataset class for the training data\n",
        "train_data = train_data = AudioDataset(\n",
        "    root=ROOT, \n",
        "    partition=\"train-clean-100\", \n",
        "    context=config['context']\n",
        ")\n",
        "\n",
        "# TODO: Create a dataset object using the AudioDataset class for the validation data\n",
        "val_data = AudioDataset(\n",
        "    root=ROOT, \n",
        "    partition=\"dev-clean\", \n",
        "    context=config['context']\n",
        ")\n",
        "\n",
        "# TODO: Create a dataset object using the AudioTestDataset class for the test data\n",
        "test_data = AudioTestDataset(\n",
        "    root=ROOT, \n",
        "    context=config['context']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:24:37.105100Z",
          "iopub.status.busy": "2024-12-31T15:24:37.104785Z",
          "iopub.status.idle": "2024-12-31T15:24:37.113609Z",
          "shell.execute_reply": "2024-12-31T15:24:37.112725Z",
          "shell.execute_reply.started": "2024-12-31T15:24:37.105072Z"
        },
        "id": "4mzoYfTKu14s",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch size     :  1024\n",
            "Context        :  40\n",
            "Input size     :  2268\n",
            "Output symbols :  42\n",
            "Train dataset samples = 36091157, batches = 35246\n",
            "Validation dataset samples = 1928204, batches = 1884\n",
            "Test dataset samples = 1934138, batches = 1889\n"
          ]
        }
      ],
      "source": [
        "# Define dataloaders for train, val and test datasets\n",
        "# Dataloaders will yield a batch of frames and phonemes of given batch_size at every iteration\n",
        "# We shuffle train dataloader but not val & test dataloader. Why?\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = train_data,\n",
        "    num_workers = 0,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = True,\n",
        "    collate_fn = train_data.collate_fn\n",
        ")\n",
        "\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = val_data,\n",
        "    num_workers = 0,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    dataset     = test_data,\n",
        "    num_workers = 0,\n",
        "    batch_size  = config['batch_size'],\n",
        "    pin_memory  = True,\n",
        "    shuffle     = False\n",
        ")\n",
        "\n",
        "\n",
        "print(\"Batch size     : \", config['batch_size'])\n",
        "print(\"Context        : \", config['context'])\n",
        "print(\"Input size     : \", (2*config['context']+1)*28)\n",
        "print(\"Output symbols : \", len(PHONEMES))\n",
        "\n",
        "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "print(\"Validation dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:27:30.225789Z",
          "iopub.status.busy": "2024-12-31T15:27:30.225475Z",
          "iopub.status.idle": "2024-12-31T15:27:36.866313Z",
          "shell.execute_reply": "2024-12-31T15:27:36.865100Z",
          "shell.execute_reply.started": "2024-12-31T15:27:30.225762Z"
        },
        "id": "n-GV3UvgLSoF",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1024, 81, 28]) torch.Size([1024])\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Testing code to check if your data loaders are working\n",
        "for i, data in enumerate(train_loader):\n",
        "    frames, phoneme = data\n",
        "    print(frames.shape, phoneme.shape)\n",
        "\n",
        "    # Visualize sample mfcc to inspect and verify everything is correctly done, especially augmentations\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.imshow(frames[0].numpy().T, aspect='auto', origin='lower', cmap='viridis')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Features')\n",
        "    plt.title('Feature Representation')\n",
        "    plt.show()\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T02:04:28.807971Z",
          "iopub.status.busy": "2024-12-24T02:04:28.807726Z",
          "iopub.status.idle": "2024-12-24T02:04:58.177819Z",
          "shell.execute_reply": "2024-12-24T02:04:58.176831Z",
          "shell.execute_reply.started": "2024-12-24T02:04:28.807951Z"
        },
        "id": "dJTrLe7J5dSc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Testing code to check if your validation data loaders are working\n",
        "all = []\n",
        "for i, data in enumerate(val_loader):\n",
        "    frames, phoneme = data\n",
        "    all.append(phoneme)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nxjwve20JRJ2"
      },
      "source": [
        "# Network Architecture\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NJzT-mRw6iy"
      },
      "source": [
        "This section defines your network architecture for the homework. We have given you a sample architecture that can easily clear the very low cutoff for the early submission deadline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:20.193972Z",
          "iopub.status.busy": "2024-12-31T15:29:20.193622Z",
          "iopub.status.idle": "2024-12-31T15:29:20.203743Z",
          "shell.execute_reply": "2024-12-31T15:29:20.202883Z",
          "shell.execute_reply.started": "2024-12-31T15:29:20.193944Z"
        },
        "id": "-YsMpN-Exafq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# This architecture will make you cross the very low cutoff\n",
        "# However, you need to run a lot of experiments to cross the medium or high cutoff\n",
        "\n",
        "class Network(nn.Module):\n",
        "    def __init__(self, input_size, output_size, dropout_rate=0.1):\n",
        "        super(Network, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            torch.nn.Linear(input_size, 2176),   \n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            \n",
        "            torch.nn.Linear(2176, 2176),\n",
        "            torch.nn.BatchNorm1d(2176),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            \n",
        "            torch.nn.Linear(2176, 2176),\n",
        "            torch.nn.BatchNorm1d(2176),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            \n",
        "            torch.nn.Linear(2176, 1536),        \n",
        "            torch.nn.BatchNorm1d(1536),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            \n",
        "            torch.nn.Linear(1536, 1024),\n",
        "            torch.nn.BatchNorm1d(1024),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "\n",
        "            torch.nn.Linear(1024, 512),\n",
        "            torch.nn.BatchNorm1d(512),\n",
        "            torch.nn.GELU(),\n",
        "            torch.nn.Dropout(dropout_rate),\n",
        "            \n",
        "            torch.nn.Linear(512, output_size)\n",
        "        )\n",
        "\n",
        "        if config['weight_initialization'] is not None:\n",
        "            self.initialize_weights()\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, torch.nn.Linear):\n",
        "                if config[\"weight_initialization\"] == \"xavier_normal\":\n",
        "                    torch.nn.init.xavier_normal_(m.weight)\n",
        "                elif config[\"weight_initialization\"] == \"xavier_uniform\":\n",
        "                    torch.nn.init.xavier_uniform_(m.weight)\n",
        "                elif config[\"weight_initialization\"] == \"kaiming_normal\":\n",
        "                    torch.nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
        "                elif config[\"weight_initialization\"] == \"kaiming_uniform\":\n",
        "                    torch.nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
        "                elif config[\"weight_initialization\"] == \"uniform\":\n",
        "                    torch.nn.init.uniform_(m.weight)\n",
        "                else:\n",
        "                    raise ValueError(\"Invalid weight_initialization value\")\n",
        "\n",
        "                # Initialize bias to 0\n",
        "                m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Flatten to a 1D vector for each data point\n",
        "        x = torch.flatten(x, start_dim=1)  # Keeps batch size, flattens the rest\n",
        "\n",
        "        return self.model(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HejoSXe3vMVU"
      },
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAhGBH7-xxth"
      },
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:23.891053Z",
          "iopub.status.busy": "2024-12-31T15:29:23.890697Z",
          "iopub.status.idle": "2024-12-31T15:29:24.267793Z",
          "shell.execute_reply": "2024-12-31T15:29:24.267100Z",
          "shell.execute_reply.started": "2024-12-31T15:29:23.891023Z"
        },
        "id": "_qtrEM1ZvLje",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define the input size\n",
        "INPUT_SIZE  = (2*config['context'] + 1) * 28 # Why is this the case?\n",
        "\n",
        "# Instantiate model and load to GPU\n",
        "model = Network(INPUT_SIZE, len(train_data.phonemes), dropout_rate=config['dropout']).to(device).cuda()\n",
        "\n",
        "# Remember, you are limited to 20 million parameters for HW1 (including ensembles)\n",
        "# Check to stay below 20 MIL Parameter limit\n",
        "assert sum(p.numel() for p in model.parameters() if p.requires_grad) < 20_000_000, \"Exceeds 20 MIL params. Any submission made to Kaggle with this model will be flagged as an AIV.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JPWu0H557ev4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummaryX==1.1.0 in c:\\users\\xulunl\\appdata\\local\\miniconda3\\envs\\idl\\lib\\site-packages (1.1.0)\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Layer                   Kernel Shape         Output Shape         # Params (K)      # Mult-Adds (M)\n",
            "====================================================================================================\n",
            "0_Linear                [2268, 2176]         [1024, 2176]             4,937.34                 4.94\n",
            "1_GELU                             -         [1024, 2176]                    -                    -\n",
            "2_Dropout                          -         [1024, 2176]                    -                    -\n",
            "3_Linear                [2176, 2176]         [1024, 2176]             4,737.15                 4.73\n",
            "4_BatchNorm1d                 [2176]         [1024, 2176]                 4.35                 0.00\n",
            "5_GELU                             -         [1024, 2176]                    -                    -\n",
            "6_Dropout                          -         [1024, 2176]                    -                    -\n",
            "7_Linear                [2176, 2176]         [1024, 2176]             4,737.15                 4.73\n",
            "8_BatchNorm1d                 [2176]         [1024, 2176]                 4.35                 0.00\n",
            "9_GELU                             -         [1024, 2176]                    -                    -\n",
            "10_Dropout                         -         [1024, 2176]                    -                    -\n",
            "11_Linear               [2176, 1536]         [1024, 1536]             3,343.87                 3.34\n",
            "12_BatchNorm1d                [1536]         [1024, 1536]                 3.07                 0.00\n",
            "13_GELU                            -         [1024, 1536]                    -                    -\n",
            "14_Dropout                         -         [1024, 1536]                    -                    -\n",
            "15_Linear               [1536, 1024]         [1024, 1024]             1,573.89                 1.57\n",
            "16_BatchNorm1d                [1024]         [1024, 1024]                 2.05                 0.00\n",
            "17_GELU                            -         [1024, 1024]                    -                    -\n",
            "18_Dropout                         -         [1024, 1024]                    -                    -\n",
            "19_Linear                [1024, 512]          [1024, 512]               524.80                 0.52\n",
            "20_BatchNorm1d                 [512]          [1024, 512]                 1.02                 0.00\n",
            "21_GELU                            -          [1024, 512]                    -                    -\n",
            "22_Dropout                         -          [1024, 512]                    -                    -\n",
            "23_Linear                  [512, 42]           [1024, 42]                21.55                 0.02\n",
            "====================================================================================================\n",
            "# Params:    19,890.60K\n",
            "# Mult-Adds: 19.87M\n",
            "----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Inspect model architecture and check to verify number of parameters of your network\n",
        "try:\n",
        "    # Install and import torchsummaryX\n",
        "    !pip install torchsummaryX==1.1.0\n",
        "    from torchsummaryX import summary\n",
        "\n",
        "    summary(model, frames.to(device))\n",
        "\n",
        "except:\n",
        "    !pip install torchsummary\n",
        "    from torchsummary import summary\n",
        "\n",
        "    summary(model, frames[0].to(device).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSk4YP63TBnD"
      },
      "source": [
        "# Define Model, Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwdxl4RiTBnD"
      },
      "source": [
        "Here we define the model, loss function, optimizer and optionally a learning rate scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:28.681502Z",
          "iopub.status.busy": "2024-12-31T15:29:28.681153Z",
          "iopub.status.idle": "2024-12-31T15:29:29.386622Z",
          "shell.execute_reply": "2024-12-31T15:29:29.385517Z",
          "shell.execute_reply.started": "2024-12-31T15:29:28.681476Z"
        },
        "id": "kZgQ7AgyTBnE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss(label_smoothing=0.05) # Defining Loss function.\n",
        "# We use CE because the task is multi-class classification\n",
        "\n",
        "# Choose an appropriate optimizer of your choice\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=1e-4)\n",
        "\n",
        "# Recommended : Define Scheduler for Learning Rate,\n",
        "# including but not limited to StepLR, MultiStep, CosineAnnealing, CosineAnnealingWithWarmRestarts, ReduceLROnPlateau, etc.\n",
        "# You can refer to Pytorch documentation for more information on how to use them.\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR (\n",
        "    optimizer,\n",
        "    max_lr=1.1e-3,\n",
        "    epochs=config[\"epochs\"],\n",
        "    steps_per_epoch=len(train_loader),\n",
        "    pct_start=0.2,\n",
        "    anneal_strategy=\"cos\",\n",
        "    div_factor=3.0,\n",
        "    final_div_factor=100.0\n",
        ")\n",
        "\n",
        "# Is your training time very high?\n",
        "# Look into mixed precision training if your GPU (Tesla T4, V100, etc) can make use of it\n",
        "# Refer - https://pytorch.org/docs/stable/notes/amp_examples.html\n",
        "# Mixed Precision Training with AMP for speedup\n",
        "use_amp  = (device == \"cuda\")\n",
        "use_bf16 = use_amp and torch.cuda.is_bf16_supported()\n",
        "amp_dtype = torch.bfloat16 if use_bf16 else torch.float16\n",
        "scaler = torch.amp.GradScaler('cuda', not use_bf16)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training and Validation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JgeNhx4x2-P"
      },
      "source": [
        "This section covers the training, and validation functions for each epoch of running your experiment with a given model architecture. The code has been provided to you, but we recommend going through the comments to understand the workflow to enable you to write these loops for future HWs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:33.552602Z",
          "iopub.status.busy": "2024-12-31T15:29:33.551839Z",
          "iopub.status.idle": "2024-12-31T15:29:33.739892Z",
          "shell.execute_reply": "2024-12-31T15:29:33.739136Z",
          "shell.execute_reply.started": "2024-12-31T15:29:33.552569Z"
        },
        "id": "XblOHEVtKab2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# CLEAR RAM!!\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:35.533310Z",
          "iopub.status.busy": "2024-12-31T15:29:35.532955Z",
          "iopub.status.idle": "2024-12-31T15:29:35.539902Z",
          "shell.execute_reply": "2024-12-31T15:29:35.539084Z",
          "shell.execute_reply.started": "2024-12-31T15:29:35.533280Z"
        },
        "id": "8wjPz7DHqKcL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion):\n",
        "    model.train()\n",
        "\n",
        "    # Freeze BN running stats \n",
        "    for m in model.modules():\n",
        "        if isinstance(m, torch.nn.BatchNorm1d):\n",
        "            m.eval()\n",
        "\n",
        "    tloss, tacc = 0.0, 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    batch_bar = tqdm(total=len(dataloader),\n",
        "                     dynamic_ncols=True,\n",
        "                     leave=False,\n",
        "                     position=0,\n",
        "                     desc='Train')\n",
        "\n",
        "    for i, (frames, phonemes) in enumerate(dataloader):\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        frames   = frames.to(device, non_blocking=True)\n",
        "        phonemes = phonemes.to(device, non_blocking=True)\n",
        "\n",
        "        amp_enabled     = (device == \"cuda\")\n",
        "        amp_dtype_local = amp_dtype  \n",
        "\n",
        "        # forward (AMP)\n",
        "        with torch.autocast(device_type=device, dtype=amp_dtype, enabled=(device==\"cuda\")):\n",
        "            logits = model(frames)\n",
        "\n",
        "        # If AMP produced non-finite logits, redo forward in pure fp32\n",
        "        if not torch.isfinite(logits).all():\n",
        "            with torch.autocast(device_type=device, enabled=False):\n",
        "                logits = model(frames)\n",
        "\n",
        "        if not torch.isfinite(logits).all():\n",
        "            print(f\"\\n[skip batch] batch={i} lr={optimizer.param_groups[0]['lr']}\")\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            scheduler.step()\n",
        "            continue\n",
        "\n",
        "        loss = criterion(logits.float(), phonemes)\n",
        "\n",
        "        if not torch.isfinite(loss):\n",
        "            print(f\"\\n[NaN/Inf loss] batch={i} lr={optimizer.param_groups[0]['lr']}\")\n",
        "            print(\"frames finite:\", torch.isfinite(frames).all().item())\n",
        "            print(\"logits finite:\", torch.isfinite(logits).all().item())\n",
        "            batch_bar.close()\n",
        "            return float(\"nan\"), 0.0\n",
        "\n",
        "        if scaler.is_enabled():\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            scaler.unscale_(optimizer)\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  \n",
        "\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  \n",
        "            optimizer.step()\n",
        "\n",
        "        # OneCycleLR step per-batch\n",
        "        scheduler.step()\n",
        "\n",
        "        # metrics \n",
        "        tloss += loss.item()\n",
        "        tacc  += (torch.argmax(logits, dim=1) == phonemes).float().mean().item()\n",
        "        num_batches += 1\n",
        "\n",
        "        batch_bar.set_postfix(\n",
        "            loss=\"{:.04f}\".format(tloss / num_batches),\n",
        "            acc=\"{:.04f}%\".format(100.0 * tacc / num_batches)\n",
        "        )\n",
        "        batch_bar.update()\n",
        "\n",
        "    batch_bar.close()\n",
        "\n",
        "    if num_batches > 0:\n",
        "        tloss /= num_batches\n",
        "        tacc  /= num_batches\n",
        "    else:\n",
        "        tloss, tacc = float(\"nan\"), 0.0\n",
        "\n",
        "    return tloss, tacc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:39.024010Z",
          "iopub.status.busy": "2024-12-31T15:29:39.023658Z",
          "iopub.status.idle": "2024-12-31T15:29:39.030046Z",
          "shell.execute_reply": "2024-12-31T15:29:39.029273Z",
          "shell.execute_reply.started": "2024-12-31T15:29:39.023980Z"
        },
        "id": "Q5npQNFH315V",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def eval(model, dataloader):\n",
        "\n",
        "    model.eval() # set model in evaluation mode\n",
        "    vloss, vacc = 0, 0 # Monitoring loss and accuracy\n",
        "    batch_bar   = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
        "\n",
        "    for i, (frames, phonemes) in enumerate(dataloader):\n",
        "\n",
        "        ### Move data to device (ideally GPU)\n",
        "        frames      = frames.to(device)\n",
        "        phonemes    = phonemes.to(device)\n",
        "\n",
        "        # makes sure that there are no gradients computed as we are not training the model now\n",
        "        with torch.inference_mode():\n",
        "            ### Forward Propagation\n",
        "            logits  = model(frames)\n",
        "            ### Loss Calculation\n",
        "            loss    = criterion(logits, phonemes)\n",
        "\n",
        "        vloss   += loss.item()\n",
        "        vacc    += torch.sum(torch.argmax(logits, dim= 1) == phonemes).item()/logits.shape[0]\n",
        "\n",
        "        # Do you think we need loss.backward() and optimizer.step() here?\n",
        "\n",
        "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(vloss / (i + 1))),\n",
        "                              acc=\"{:.04f}%\".format(float(vacc*100 / (i + 1))))\n",
        "        batch_bar.update()\n",
        "\n",
        "    batch_bar.close()\n",
        "    vloss   /= len(val_loader)\n",
        "    vacc    /= len(val_loader)\n",
        "\n",
        "    return vloss, vacc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMd_XxPku5qp"
      },
      "source": [
        "# Weights and Biases Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjIbhR1wwbgI"
      },
      "source": [
        "This section is to enable logging metrics and files with Weights and Biases. Please refer to wandb documentationa and recitation 0 that covers the use of weights and biases for logging, hyperparameter tuning and monitoring your runs for your homeworks. Using this tool makes it very easy to show results when submitting your code and models for homeworks, and also extremely useful for study groups to organize and run ablations under a single team in wandb.\n",
        "\n",
        "We have written code for you to make use of it out of the box, so that you start using wandb for all your HWs from the beginning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:45.702653Z",
          "iopub.status.busy": "2024-12-31T15:29:45.702239Z",
          "iopub.status.idle": "2024-12-31T15:29:52.086338Z",
          "shell.execute_reply": "2024-12-31T15:29:52.085568Z",
          "shell.execute_reply.started": "2024-12-31T15:29:45.702611Z"
        },
        "id": "SCDYx5VEu6qI",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m [wandb.login()] Changing session credentials to explicit value for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\xulunl\\_netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login(key=\"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\") #API Key is in your wandb account, under settings (wandb.ai/settings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:29:54.895747Z",
          "iopub.status.busy": "2024-12-31T15:29:54.895254Z",
          "iopub.status.idle": "2024-12-31T15:30:01.107921Z",
          "shell.execute_reply": "2024-12-31T15:30:01.106993Z",
          "shell.execute_reply.started": "2024-12-31T15:29:54.895723Z"
        },
        "id": "xvUnYd3Bw2up",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing new WanDB run...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.24.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>c:\\Users\\xulunl\\Desktop\\Intro to DeepLearning\\HW1\\HW1P2\\wandb\\run-20260205_140918-769ue6rw</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2/runs/769ue6rw' target=\"_blank\">first-run1</a></strong> to <a href='https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2' target=\"_blank\">https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2/runs/769ue6rw' target=\"_blank\">https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2/runs/769ue6rw</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create your wandb run\n",
        "RESUME_OLD_RUN = False\n",
        "\n",
        "if RESUME_OLD_RUN == True:\n",
        "    print(\"Resuming previous WanDB run...\")\n",
        "    run = wandb.init(\n",
        "        name    = \"first-run1\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "        id     = \"\", ### Insert specific run id here if you want to resume a previous run\n",
        "        resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "        project = \"hw1p2\", ### Project should be created in your wandb account\n",
        "        config  = config ### Wandb Config for your run\n",
        "    )\n",
        "else:\n",
        "    print(\"Initializing new WanDB run...\")\n",
        "    run = wandb.init(\n",
        "        name    = \"first-run1\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "        reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "        project = \"hw1p2\", ### Project should be created in your wandb account\n",
        "        config  = config ### Wandb Config for your run\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:30:12.132356Z",
          "iopub.status.busy": "2024-12-31T15:30:12.131957Z",
          "iopub.status.idle": "2024-12-31T15:30:12.142067Z",
          "shell.execute_reply": "2024-12-31T15:30:12.141280Z",
          "shell.execute_reply.started": "2024-12-31T15:30:12.132322Z"
        },
        "id": "wft15E_IxYFi",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Linked 1 file into the W&B run directory (hardlinks); call wandb.save again to sync new files.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['c:\\\\Users\\\\xulunl\\\\Desktop\\\\Intro to DeepLearning\\\\HW1\\\\HW1P2\\\\wandb\\\\run-20260205_140918-769ue6rw\\\\files\\\\model_arch.txt']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "### Save your model architecture as a string with str(model)\n",
        "model_arch  = str(model)\n",
        "\n",
        "### Save it in a txt file\n",
        "arch_file   = open(\"model_arch.txt\", \"w\")\n",
        "file_write  = arch_file.write(model_arch)\n",
        "arch_file.close()\n",
        "\n",
        "### log it in your wandb run with wandb.save()\n",
        "wandb.save('model_arch.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nclx_04fu7Dd"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdLMWfEpyGOB"
      },
      "source": [
        "Now, it is time to finally run your ablations! Have fun!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-31T15:30:23.248062Z",
          "iopub.status.busy": "2024-12-31T15:30:23.247745Z"
        },
        "id": "4NNCA5DDTBnO",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4a994f0dd7422f8ab7add48d088c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b9a6dc82fd6c43f5b3bec3b1038c0758",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 68.2216%\tTrain Loss 1.3140\t Learning Rate 0.0003667\n",
            "\tVal Acc 78.9725%\tVal Loss 0.9567\n",
            "Saved best epoch 1: 78.9725%\n",
            "\n",
            "Epoch 2/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fe65f6f9e65411c9f7948a33d0c93ce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b2868fd2b954feab49055f76a3cc2aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 73.9484%\tTrain Loss 1.1264\t Learning Rate 0.0003888\n",
            "\tVal Acc 80.9927%\tVal Loss 0.8944\n",
            "Saved best epoch 2: 80.9927%\n",
            "\n",
            "Epoch 3/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "700bb8c276174100a356a601f3a3c181",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1f96538c0a3b4ea7ae6786e2e17ff5ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 75.7000%\tTrain Loss 1.0706\t Learning Rate 0.0004525\n",
            "\tVal Acc 82.0304%\tVal Loss 0.8638\n",
            "Saved best epoch 3: 82.0304%\n",
            "\n",
            "Epoch 4/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "20d001955bb54bee9ee40fc2cf04d03f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdbf1d5236c442f894c6d207047ce9de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 76.7236%\tTrain Loss 1.0388\t Learning Rate 0.0005500\n",
            "\tVal Acc 82.5570%\tVal Loss 0.8498\n",
            "Saved best epoch 4: 82.5570%\n",
            "\n",
            "Epoch 5/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "668d09dac5c941f6ae60b1176baf8038",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e99a6a0dda664e779fefdacd98d92f34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 77.3293%\tTrain Loss 1.0203\t Learning Rate 0.0006697\n",
            "\tVal Acc 82.9982%\tVal Loss 0.8361\n",
            "Saved best epoch 5: 82.9982%\n",
            "\n",
            "Epoch 6/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a90db746eb41eb9b540affc8251cae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98e512b3255d4d11a889fdd588932606",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 77.7026%\tTrain Loss 1.0091\t Learning Rate 0.0007970\n",
            "\tVal Acc 83.2646%\tVal Loss 0.8302\n",
            "Saved best epoch 6: 83.2646%\n",
            "\n",
            "Epoch 7/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fea081ff975e44a8b9c49ff41ea6ddca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9e7214a32d32462ca7a694880ed985dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 78.1019%\tTrain Loss 0.9971\t Learning Rate 0.0009167\n",
            "\tVal Acc 83.4425%\tVal Loss 0.8244\n",
            "Saved best epoch 7: 83.4425%\n",
            "\n",
            "Epoch 8/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "17410d8049f94e139a9eebe43c0e7358",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26e3e5f958af495c87998fb6b1268b8f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 78.5152%\tTrain Loss 0.9843\t Learning Rate 0.0010142\n",
            "\tVal Acc 83.8223%\tVal Loss 0.8143\n",
            "Saved best epoch 8: 83.8223%\n",
            "\n",
            "Epoch 9/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "df0f893f53304417a0fab9cf11274806",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "31fc6c027ec14a89b86fcbb054c54c8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 78.7104%\tTrain Loss 0.9787\t Learning Rate 0.0010779\n",
            "\tVal Acc 84.0438%\tVal Loss 0.8077\n",
            "Saved best epoch 9: 84.0438%\n",
            "\n",
            "Epoch 10/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "86d3a82b5f84434b8ea31d6900172906",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb81663604dc49858b644ea65c33df2a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 79.1423%\tTrain Loss 0.9656\t Learning Rate 0.0011000\n",
            "\tVal Acc 84.2072%\tVal Loss 0.8037\n",
            "Saved best epoch 10: 84.2072%\n",
            "\n",
            "Epoch 11/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ad04d7f2bea4ecca750246f9611b2d8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9394086cd0b24fbca393829c2276d87e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 79.5599%\tTrain Loss 0.9532\t Learning Rate 0.0010979\n",
            "\tVal Acc 84.4464%\tVal Loss 0.7967\n",
            "Saved best epoch 11: 84.4464%\n",
            "\n",
            "Epoch 12/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "477693afa9004f5094c68d52cc02ecbf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7ec2ed1018bc4cb298fb6560bc67a905",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 79.8081%\tTrain Loss 0.9455\t Learning Rate 0.0010917\n",
            "\tVal Acc 84.5744%\tVal Loss 0.7941\n",
            "Saved best epoch 12: 84.5744%\n",
            "\n",
            "Epoch 13/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2eb4240327940dd8daba643bcefed90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4166eeb575f148b0ac9c06bf328386f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 80.1224%\tTrain Loss 0.9357\t Learning Rate 0.0010813\n",
            "\tVal Acc 84.6752%\tVal Loss 0.7912\n",
            "Saved best epoch 13: 84.6752%\n",
            "\n",
            "Epoch 14/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e96debc1a47545efa1d5d0b01aef49ff",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53bda5e4ba0d4d6388194d3530505302",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 80.2511%\tTrain Loss 0.9320\t Learning Rate 0.0010669\n",
            "\tVal Acc 84.7735%\tVal Loss 0.7883\n",
            "Saved best epoch 14: 84.7735%\n",
            "\n",
            "Epoch 15/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bc943df6dd574d748755ff06f0516b93",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "06bf55f6fb104b338d0b567108b14b91",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 80.4784%\tTrain Loss 0.9254\t Learning Rate 0.0010486\n",
            "\tVal Acc 84.8998%\tVal Loss 0.7861\n",
            "Saved best epoch 15: 84.8998%\n",
            "\n",
            "Epoch 16/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16d8d08f148c44ddb79e953b20fb656c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4173ee05ef0a47fc9d84923987bba909",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 80.7285%\tTrain Loss 0.9173\t Learning Rate 0.0010266\n",
            "\tVal Acc 84.9971%\tVal Loss 0.7824\n",
            "Saved best epoch 16: 84.9971%\n",
            "\n",
            "Epoch 17/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c0aa4b30e1054b4ea125b32214c2ba0f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d52f45981ba4fa58b80d2264759f85f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 80.8742%\tTrain Loss 0.9133\t Learning Rate 0.0010009\n",
            "\tVal Acc 85.1372%\tVal Loss 0.7778\n",
            "Saved best epoch 17: 85.1372%\n",
            "\n",
            "Epoch 18/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1097ef458844405bb15498cc51614fca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e24c4256349145489a8c200a30f6e7e6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 81.0684%\tTrain Loss 0.9072\t Learning Rate 0.0009718\n",
            "\tVal Acc 85.1878%\tVal Loss 0.7766\n",
            "Saved best epoch 18: 85.1878%\n",
            "\n",
            "Epoch 19/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ceed1e2503424796a47907a60ad41c9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "528e751088be460193fcfa052c8e94e2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 81.2346%\tTrain Loss 0.9021\t Learning Rate 0.0009394\n",
            "\tVal Acc 85.2652%\tVal Loss 0.7764\n",
            "Saved best epoch 19: 85.2652%\n",
            "\n",
            "Epoch 20/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d4e147dc4be4694b6277facf7a229e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6514ef048d8b418fb2f57760e86f7008",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 81.5367%\tTrain Loss 0.8926\t Learning Rate 0.0009042\n",
            "\tVal Acc 85.3658%\tVal Loss 0.7723\n",
            "Saved best epoch 20: 85.3658%\n",
            "\n",
            "Epoch 21/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4037c8722383441bbe2d46ba29586702",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d9b58e810b341659375723e5975346a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 81.5034%\tTrain Loss 0.8939\t Learning Rate 0.0008662\n",
            "\tVal Acc 85.4182%\tVal Loss 0.7712\n",
            "Saved best epoch 21: 85.4182%\n",
            "\n",
            "Epoch 22/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d150e7893c742959b4932bc60232a41",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2da1d0ba69bd4035a2d99548b3ea7996",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 81.8387%\tTrain Loss 0.8833\t Learning Rate 0.0008259\n",
            "\tVal Acc 85.4752%\tVal Loss 0.7683\n",
            "Saved best epoch 22: 85.4752%\n",
            "\n",
            "Epoch 23/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e14866ecf6dd49df8f239df0997f4273",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2bbb2162c5ba4ae2b4b2f91c9bb1fbd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 81.8675%\tTrain Loss 0.8829\t Learning Rate 0.0007835\n",
            "\tVal Acc 85.5964%\tVal Loss 0.7667\n",
            "Saved best epoch 23: 85.5964%\n",
            "\n",
            "Epoch 24/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8495f4a5df64f7e948edbd6eb119e80",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9079303a14274f95856441be54a4974f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.1099%\tTrain Loss 0.8750\t Learning Rate 0.0007393\n",
            "\tVal Acc 85.7018%\tVal Loss 0.7637\n",
            "Saved best epoch 24: 85.7018%\n",
            "\n",
            "Epoch 25/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65f82343cf824a20b60d241d9175813e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0d42592bc8b41beb2a6275cd80b6e1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.2655%\tTrain Loss 0.8704\t Learning Rate 0.0006937\n",
            "\tVal Acc 85.7498%\tVal Loss 0.7610\n",
            "Saved best epoch 25: 85.7498%\n",
            "\n",
            "Epoch 26/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b99106f035f240d799eb1cd4ac339925",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3e8cb65980154f43937ff26f121e8b84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.4278%\tTrain Loss 0.8653\t Learning Rate 0.0006470\n",
            "\tVal Acc 85.8221%\tVal Loss 0.7610\n",
            "Saved best epoch 26: 85.8221%\n",
            "\n",
            "Epoch 27/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84a967c3f7e047fe8a71082974bd47e5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e9ce1095a3e547bd89560419da4f41bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.5725%\tTrain Loss 0.8607\t Learning Rate 0.0005996\n",
            "\tVal Acc 85.8895%\tVal Loss 0.7566\n",
            "Saved best epoch 27: 85.8895%\n",
            "\n",
            "Epoch 28/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4bb321b9716456a9cbb0f87238b9420",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0dae3898344d479ea9eac680888cd31d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.7185%\tTrain Loss 0.8561\t Learning Rate 0.0005518\n",
            "\tVal Acc 85.9481%\tVal Loss 0.7585\n",
            "Saved best epoch 28: 85.9481%\n",
            "\n",
            "Epoch 29/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0fffc8a4134b4c7799215135f44b83f9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8aade07a9fd48ecb8155a173d41ba75",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.8916%\tTrain Loss 0.8509\t Learning Rate 0.0005041\n",
            "\tVal Acc 86.0332%\tVal Loss 0.7541\n",
            "Saved best epoch 29: 86.0332%\n",
            "\n",
            "Epoch 30/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a50b593842f14754ad42271d13f049ac",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb8301f46d4345da9522a0548c4dca31",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 82.8530%\tTrain Loss 0.8521\t Learning Rate 0.0004566\n",
            "\tVal Acc 86.0675%\tVal Loss 0.7541\n",
            "Saved best epoch 30: 86.0675%\n",
            "\n",
            "Epoch 31/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85b431bc8fa74b31b88810cfd0c163bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe800415f8bd4e07b81139c5fd552b28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.1106%\tTrain Loss 0.8439\t Learning Rate 0.0004100\n",
            "\tVal Acc 86.1235%\tVal Loss 0.7515\n",
            "Saved best epoch 31: 86.1235%\n",
            "\n",
            "Epoch 32/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b648a83247343c7ba8979ef4e816045",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f7cbb3563754ffab226e3cc8bd19f85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.2054%\tTrain Loss 0.8408\t Learning Rate 0.0003643\n",
            "\tVal Acc 86.1782%\tVal Loss 0.7507\n",
            "Saved best epoch 32: 86.1782%\n",
            "\n",
            "Epoch 33/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8545659b3014465f8f5ec5e38d8bc8c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16f46181b0c94c16b4791dd81d3f7ab4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.3027%\tTrain Loss 0.8383\t Learning Rate 0.0003202\n",
            "\tVal Acc 86.2279%\tVal Loss 0.7495\n",
            "Saved best epoch 33: 86.2279%\n",
            "\n",
            "Epoch 34/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2597a04f6ba4cb79ff6f0beefd6413b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6529b3e7361d4f59b25b133e5c10114d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.4993%\tTrain Loss 0.8319\t Learning Rate 0.0002777\n",
            "\tVal Acc 86.2488%\tVal Loss 0.7486\n",
            "Saved best epoch 34: 86.2488%\n",
            "\n",
            "Epoch 35/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec3eb7d31d784b1e8ce9553ac2fcd59a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2887df24c6c14ce8bbd4e0bc9da85d5e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.5652%\tTrain Loss 0.8300\t Learning Rate 0.0002374\n",
            "\tVal Acc 86.3144%\tVal Loss 0.7474\n",
            "Saved best epoch 35: 86.3144%\n",
            "\n",
            "Epoch 36/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d89602a9e8c42d1b40be079baa89f86",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "02105a0fd34a45f083a6ce303af3c9f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.6200%\tTrain Loss 0.8285\t Learning Rate 0.0001995\n",
            "\tVal Acc 86.3362%\tVal Loss 0.7466\n",
            "Saved best epoch 36: 86.3362%\n",
            "\n",
            "Epoch 37/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c047e94f0ed4b2e843092b7c06fa20f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0e500c7265da4511a3eefd9564827e61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.6939%\tTrain Loss 0.8262\t Learning Rate 0.0001642\n",
            "\tVal Acc 86.3733%\tVal Loss 0.7452\n",
            "Saved best epoch 37: 86.3733%\n",
            "\n",
            "Epoch 38/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ea81281679f04703bd18e2843ece35c7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "730daf562b9a42dea692ae352d54a568",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.8957%\tTrain Loss 0.8200\t Learning Rate 0.0001319\n",
            "\tVal Acc 86.4012%\tVal Loss 0.7459\n",
            "Saved best epoch 38: 86.4012%\n",
            "\n",
            "Epoch 39/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "140b6d7b1b9345ba874574f7f9102ed6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b467d0ddd692462babb18d3a6e9b5211",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.8053%\tTrain Loss 0.8225\t Learning Rate 0.0001028\n",
            "\tVal Acc 86.4115%\tVal Loss 0.7447\n",
            "Saved best epoch 39: 86.4115%\n",
            "\n",
            "Epoch 40/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73bb29b70c404745bd8a2bf16b18d2dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd22ca2e74a14495bbdf5bef2f17983f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.9926%\tTrain Loss 0.8168\t Learning Rate 0.0000771\n",
            "\tVal Acc 86.4400%\tVal Loss 0.7437\n",
            "Saved best epoch 40: 86.4400%\n",
            "\n",
            "Epoch 41/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b717c626386940bda7f9853881de4595",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7199cd921cc4d8ab43490088f761185",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 84.0014%\tTrain Loss 0.8166\t Learning Rate 0.0000550\n",
            "\tVal Acc 86.4468%\tVal Loss 0.7437\n",
            "Saved best epoch 41: 86.4468%\n",
            "\n",
            "Epoch 42/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "640c4f1cd7724066b0f7d371f83ea817",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98644005db0d477f920a12cb3eecfc70",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 84.0811%\tTrain Loss 0.8143\t Learning Rate 0.0000367\n",
            "\tVal Acc 86.4700%\tVal Loss 0.7437\n",
            "Saved best epoch 42: 86.4700%\n",
            "\n",
            "Epoch 43/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e24b2b20fc7a43cea1118c8ba3a3cd00",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c152848f1d5e4f4584ed91e6f3aba977",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.9910%\tTrain Loss 0.8170\t Learning Rate 0.0000223\n",
            "\tVal Acc 86.4773%\tVal Loss 0.7432\n",
            "Saved best epoch 43: 86.4773%\n",
            "\n",
            "Epoch 44/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "072762de6504421daa950c53642f0fe4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2acebf18a6a4ed393eed1ce7c32d657",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.9572%\tTrain Loss 0.8181\t Learning Rate 0.0000120\n",
            "\tVal Acc 86.4879%\tVal Loss 0.7432\n",
            "Saved best epoch 44: 86.4879%\n",
            "\n",
            "Epoch 45/45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "83c641e906a74198a58b95a9512f2c99",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Train:   0%|          | 0/35246 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8514130c0834fe4aa7aa0f37b0b5ba9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Val:   0%|          | 0/1884 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\tTrain Acc 83.9873%\tTrain Loss 0.8173\t Learning Rate 0.0000058\n",
            "\tVal Acc 86.4896%\tVal Loss 0.7431\n",
            "Saved best epoch 45: 86.4896%\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "ckpt_dir = \"./checkpoints\"\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "best_val_acc = -1.0\n",
        "\n",
        "\n",
        "# Iterate over number of epochs to train and evaluate your model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "wandb.watch(model, log=\"all\")\n",
        "\n",
        "for epoch in range(config[\"epochs\"]):\n",
        "\n",
        "    print(\"\\nEpoch {}/{}\".format(epoch+1, config['epochs']))\n",
        "\n",
        "    curr_lr                 = float(optimizer.param_groups[0]['lr'])\n",
        "    train_loss, train_acc   = train(model, train_loader, optimizer, criterion)\n",
        "    val_loss, val_acc       = eval(model, val_loader)\n",
        "\n",
        "    print(\"\\tTrain Acc {:.04f}%\\tTrain Loss {:.04f}\\t Learning Rate {:.07f}\".format(train_acc*100, train_loss, curr_lr))\n",
        "    print(\"\\tVal Acc {:.04f}%\\tVal Loss {:.04f}\".format(val_acc*100, val_loss))\n",
        "\n",
        "    ## Log metrics at each epoch in your run\n",
        "    # Optionally, you can log at each batch inside train/eval functions\n",
        "    # (explore wandb documentation/wandb recitation)\n",
        "    wandb.log({'train_acc': train_acc*100, 'train_loss': train_loss,\n",
        "               'val_acc': val_acc*100, 'valid_loss': val_loss, 'lr': curr_lr})\n",
        "    \n",
        "    # always save the last epoch\n",
        "    torch.save({\n",
        "        \"epoch\": epoch,\n",
        "        \"model\": model.state_dict(),\n",
        "        \"optimizer\": optimizer.state_dict(),\n",
        "        \"scheduler\": scheduler.state_dict(),\n",
        "        \"scaler\": scaler.state_dict(),\n",
        "        \"best_val_acc\": best_val_acc,\n",
        "    }, os.path.join(ckpt_dir, \"last.pt\"))\n",
        "\n",
        "    # save the best epoch\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save({\n",
        "            \"epoch\": epoch,\n",
        "            \"model\": model.state_dict(),\n",
        "            \"optimizer\": optimizer.state_dict(),\n",
        "            \"scheduler\": scheduler.state_dict(),\n",
        "            \"scaler\": scaler.state_dict(),\n",
        "            \"best_val_acc\": best_val_acc,\n",
        "        }, os.path.join(ckpt_dir, \"best.pt\"))\n",
        "        print(f\"Saved best epoch {epoch+1}: {best_val_acc*100:.4f}%\")\n",
        "\n",
        "\n",
        "    # If using a scheduler, step the learning rate here, otherwise comment this line\n",
        "    # Depending on the scheduler in use, you may or may not need to pass in a metric into the step function, so read the docs well\n",
        "\n",
        "    ## HIGHLY RECOMMENDED: Save model checkpoint in drive and/or wandb if accuracy is better than your current best accuracy\n",
        "    ## This enables you to resume training at anytime, without having to start from scratch.\n",
        "    ## Refer to Recitation 0.24 to learn how to implement this: https://www.youtube.com/watch?v=-TCH0DbUEKM&list=PLp-0K3kfddPw2D5CeA09lsx_oNy9E"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kXwf5YUo_4A"
      },
      "source": [
        "# Testing and submission to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI1hSFYLpJvH"
      },
      "source": [
        "Before we get to the following code, make sure to see the format of submission given in *sample_submission.csv*. Once you have done so, it is time to fill the following function to complete your inference on test data. Refer the eval function from previous cells to get an idea of how to go about completing this function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T02:20:10.371165Z",
          "iopub.status.busy": "2024-12-24T02:20:10.370733Z",
          "iopub.status.idle": "2024-12-24T02:20:10.378449Z",
          "shell.execute_reply": "2024-12-24T02:20:10.377340Z",
          "shell.execute_reply.started": "2024-12-24T02:20:10.371126Z"
        },
        "id": "ijLrIJFl5dSf",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GENERATING TEST PREDICTIONS\n",
            "\n",
            " Using Test-Time Augmentation\n",
            "Running TTA with 5 passes...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8714f2507c224458a63b29a772f7970b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Pass 1/5:   0%|          | 0/1889 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed TTA pass 1/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce5ccc61c6c94cfc9066f67716a43f9d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Pass 2/5:   0%|          | 0/1889 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed TTA pass 2/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2271f9878ef4fcc9bede69cb42a292f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Pass 3/5:   0%|          | 0/1889 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed TTA pass 3/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcb75a6f91024da8af33a958bcab436d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Pass 4/5:   0%|          | 0/1889 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed TTA pass 4/5\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd08bafb43ae405980f91754da744a26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "TTA Pass 5/5:   0%|          | 0/1889 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Completed TTA pass 5/5\n",
            "Averaging predictions...\n",
            "\n",
            "Sample predictions: ['IY', 'F', 'AY', 'AY', 'AY', 'CH', 'CH', 'OW', 'CH', 'CH']\n",
            "TTA complete! Generated 1934138 predictions\n",
            "\n",
            " Generated 1934138 predictions\n",
            " Submission saved: submission_tta.csv\n",
            " Total predictions: 1934138\n"
          ]
        }
      ],
      "source": [
        "def test(model, test_loader):\n",
        "    \"\"\"Simple test prediction without TTA\"\"\"\n",
        "    model.eval()\n",
        "    test_predictions = []\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        for i, mfccs in enumerate(tqdm(test_loader)):\n",
        "            mfccs = mfccs.to(device)\n",
        "            logits = model(mfccs)\n",
        "            predicted_phonemes = torch.argmax(logits, dim=1)\n",
        "            \n",
        "            for idx in predicted_phonemes:\n",
        "                test_predictions.append(PHONEMES[idx.item()])\n",
        "    \n",
        "    # Sanity check\n",
        "    sample_predictions = test_predictions[:10]\n",
        "    if not isinstance(sample_predictions[0], str):\n",
        "        print(f\" ERROR: Predictions should be phoneme STRINGS!\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\nSample predictions:\", sample_predictions)\n",
        "    print(\"\\nPredictions Generated successfully!\")\n",
        "    return test_predictions\n",
        "\n",
        "\n",
        "\n",
        "def test_with_tta(model, test_loader, n_tta=5):\n",
        "    \"\"\"\n",
        "    Test with Test-Time Augmentation\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    all_predictions = []\n",
        "    \n",
        "    print(f\"Running TTA with {n_tta} passes...\")\n",
        "    \n",
        "    for tta_idx in range(n_tta):\n",
        "        predictions = []\n",
        "        \n",
        "        with torch.inference_mode():\n",
        "            batch_bar = tqdm(total=len(test_loader), \n",
        "                           dynamic_ncols=True, \n",
        "                           position=0, \n",
        "                           leave=False, \n",
        "                           desc=f'TTA Pass {tta_idx+1}/{n_tta}')\n",
        "            \n",
        "            for mfccs in test_loader:\n",
        "                mfccs = mfccs.to(device)\n",
        "                \n",
        "                # Add slight noise for diversity\n",
        "                if tta_idx > 0:\n",
        "                    noise = torch.randn_like(mfccs) * 0.01\n",
        "                    mfccs = mfccs + noise\n",
        "                \n",
        "                logits = model(mfccs)\n",
        "                predictions.append(logits.cpu())\n",
        "                \n",
        "                batch_bar.update()\n",
        "            \n",
        "            batch_bar.close()\n",
        "        \n",
        "        all_predictions.append(torch.cat(predictions))\n",
        "        print(f\"Completed TTA pass {tta_idx+1}/{n_tta}\")\n",
        "    \n",
        "    # Average predictions\n",
        "    print(\"Averaging predictions...\")\n",
        "    avg_logits = torch.stack(all_predictions).mean(dim=0)\n",
        "    final_pred = torch.argmax(avg_logits, dim=1)\n",
        "    \n",
        "    # Convert indices to phoneme strings\n",
        "    test_predictions = []\n",
        "    for idx in final_pred:\n",
        "        test_predictions.append(PHONEMES[idx.item()])\n",
        "    \n",
        "    # Sanity check\n",
        "    sample_predictions = test_predictions[:10]\n",
        "    if not isinstance(sample_predictions[0], str):\n",
        "        print(f\" ERROR: Predictions should be phoneme STRINGS!\")\n",
        "        return\n",
        "    \n",
        "    print(\"\\nSample predictions:\", sample_predictions)\n",
        "    print(f\"TTA complete! Generated {len(test_predictions)} predictions\")\n",
        "    \n",
        "    return test_predictions\n",
        "\n",
        "USE_TTA = True  \n",
        "\n",
        "print(\"GENERATING TEST PREDICTIONS\")\n",
        "\n",
        "if USE_TTA:\n",
        "    print(\"\\n Using Test-Time Augmentation\")\n",
        "    test_predictions = test_with_tta(model, test_loader, n_tta=5)\n",
        "else:\n",
        "    print(\"\\n Using Simple Prediction\")\n",
        "    test_predictions = test(model, test_loader)\n",
        "\n",
        "print(f\"\\n Generated {len(test_predictions)} predictions\")\n",
        "\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"id\": np.arange(len(test_predictions)),\n",
        "    \"label\": test_predictions\n",
        "})\n",
        "\n",
        "filename = 'submission_tta.csv' if USE_TTA else 'submission_simple.csv'\n",
        "submission.to_csv(filename, index=False)\n",
        "\n",
        "print(f\" Submission saved: {filename}\")\n",
        "print(f\" Total predictions: {len(submission)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T02:21:22.050782Z",
          "iopub.status.busy": "2024-12-24T02:21:22.050471Z",
          "iopub.status.idle": "2024-12-24T02:22:10.946756Z",
          "shell.execute_reply": "2024-12-24T02:22:10.945858Z",
          "shell.execute_reply.started": "2024-12-24T02:21:22.050753Z"
        },
        "id": "wG9v6Xmxu7wp",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "65310dd1bc3245e5b6260e2bb9afe2f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1889 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample predictions: ['IY', 'F', 'AY', 'AY', 'AY', 'CH', 'CH', 'OW', 'CH', 'CH']\n",
            "\n",
            "Predictions Generated successfully!\n"
          ]
        }
      ],
      "source": [
        "# Generate model test predictions\n",
        "\n",
        "predictions = test(model, test_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T02:22:12.849873Z",
          "iopub.status.busy": "2024-12-24T02:22:12.849571Z",
          "iopub.status.idle": "2024-12-24T02:22:14.184114Z",
          "shell.execute_reply": "2024-12-24T02:22:14.183417Z",
          "shell.execute_reply.started": "2024-12-24T02:22:12.849849Z"
        },
        "id": "_I6AVEY45dSg",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "submission.csv file created successfully!\n"
          ]
        }
      ],
      "source": [
        "### Create CSV file with predictions\n",
        "\n",
        "with open(\"./submission.csv\", \"w+\") as f:\n",
        "    f.write(\"id,label\\n\")\n",
        "    for i in range(len(predictions)):\n",
        "        f.write(\"{},{}\\n\".format(i, predictions[i]))\n",
        "\n",
        "    print(\"submission.csv file created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-24T02:22:17.280785Z",
          "iopub.status.busy": "2024-12-24T02:22:17.280510Z",
          "iopub.status.idle": "2024-12-24T02:22:18.714924Z",
          "shell.execute_reply": "2024-12-24T02:22:18.714234Z",
          "shell.execute_reply.started": "2024-12-24T02:22:17.280761Z"
        },
        "id": "6Wf-P25TXU0N",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>▃▃▄▄▅▆▇▇███████▇▇▇▇▆▆▆▅▅▄▄▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▄▄▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>train_loss</td><td>█▅▅▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▄▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>valid_loss</td><td>█▆▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr</td><td>1e-05</td></tr><tr><td>train_acc</td><td>83.98728</td></tr><tr><td>train_loss</td><td>0.81729</td></tr><tr><td>val_acc</td><td>86.48964</td></tr><tr><td>valid_loss</td><td>0.7431</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">first-run1</strong> at: <a href='https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2/runs/73shzbs2' target=\"_blank\">https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2/runs/73shzbs2</a><br> View project at: <a href='https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2' target=\"_blank\">https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>.\\wandb\\run-20260201_023415-73shzbs2\\logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "### Finish your wandb run\n",
        "run.finish()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvbyxVa67ev6"
      },
      "source": [
        "# Submit to kaggle competition using kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "execution": {
          "execution_failed": "2024-12-24T01:53:07.886Z"
        },
        "id": "LjcammuCxMKN",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.8.3 / client 1.6.14)\n",
            "Successfully submitted to HW1P2_Spring_2026_Student_Competition\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0.00/21.3M [00:00<?, ?B/s]\n",
            "  0%|          | 16.0k/21.3M [00:00<03:30, 106kB/s]\n",
            " 33%|███▎      | 7.00M/21.3M [00:00<00:00, 35.1MB/s]\n",
            "100%|██████████| 21.3M/21.3M [00:00<00:00, 34.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "if \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
        "    # If on kaggle:\n",
        "    !kaggle competitions submit -c hw-1-p-2-spring-2026-student-competition -f submission.csv -m \"Test Submission\"\n",
        "else:\n",
        "    # If NOT on kaggle:\n",
        "    # Adjust path of '/content/submission.csv' if necessary\n",
        "     !kaggle competitions submit -c hw-1-p-2-spring-2026-student-competition -f ./submission.csv -m \"Test Submission\"\n",
        "\n",
        "### If this fails, you can download the csv file and then submit directly on the kaggle competition page"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Zb7jyfV7ev6"
      },
      "source": [
        "## TODO: DO NOT MODIFY, RUN AS IS\n",
        "#### Generate a model_metadata.json file to save your model's data (due 48 hours after Kaggle submission deadline OR the day of slack submission)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "5wHrc5VV7ev6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ saved model data saved to: 'model_metadata_2026-02-05_14-11.json'\n",
            "REQUIRED to submit to Autolab if these are the best model weights.\n"
          ]
        }
      ],
      "source": [
        "import json, os, sys, torch, zipfile, datetime\n",
        "################################\n",
        "# TODO: Keep the model_metadata.json\n",
        "# file safe for submission later.\n",
        "################################\n",
        "def generate_model_submission_file():\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
        "    json_filename = f\"model_metadata_{timestamp}.json\"\n",
        "\n",
        "    # Create JSON with parameter count, model architecture, and predictions\n",
        "    output_json = {\n",
        "        \"parameter_count\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "        \"model_architecture\": str(model),\n",
        "    }\n",
        "\n",
        "    # Save metadata JSON\n",
        "    with open(json_filename, \"w\") as f:\n",
        "        json.dump(output_json, f, indent=2)\n",
        "\n",
        "    # Download / display link depending on environment\n",
        "    if \"google.colab\" in sys.modules and \"COLAB_GPU\" in os.environ:\n",
        "        from google.colab import files\n",
        "        files.download(json_filename)\n",
        "    elif \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ:\n",
        "        from IPython.display import FileLink, display\n",
        "        print(\"#\" * 100)\n",
        "        print(f\"Your submission file `{json_filename}` has been generated.\")\n",
        "        print(\"TODO: Click the link below.\")\n",
        "        print(\"1. The file will open in a new tab.\")\n",
        "        print(\"2. Right-click anywhere in the new tab and select 'Save As...'\")\n",
        "        print(\"3. Save the file to your computer with the `.json` extension.\")\n",
        "        print(\"You MUST submit this file to Autolab if this is your best submission.\")\n",
        "        print(\"#\" * 100 + \"\\n\")\n",
        "        display(FileLink(json_filename))\n",
        "    else:\n",
        "        print(f\"✅ saved model data saved to: '{json_filename}'\")\n",
        "        print(\"REQUIRED to submit to Autolab if these are the best model weights.\")\n",
        "\n",
        "generate_model_submission_file()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRWJQGmD7ev7"
      },
      "source": [
        "# Final Code Submission Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qo31VIEM7ev7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "####################################\n",
        "#             README\n",
        "####################################\n",
        "\n",
        "README = \"\"\"\n",
        "- **Model**: 7-layer Diamond MLP architecture with layers [2268→2176→2176→2176→1536→1024→512→42]. \n",
        "  Uses GELU activations, BatchNorm1d after each hidden layer (except first), and Dropout(0.1). \n",
        "  Context window of 40 frames (81 total frames including center). ~19.89M trainable parameters.\n",
        "\n",
        "- **Training Strategy**: AdamW optimizer (lr=0.001, weight_decay=0.001) with OneCycleLR scheduler \n",
        "  over 45 epochs. CrossEntropyLoss criterion. Mixed precision training (AMP) with GradScaler. \n",
        "  Gradient clipping (max_norm=1.0). Batch size 1024. Xavier normal weight initialization.\n",
        "\n",
        "- **Augmentations**: SpecAugment-style augmentation using torchaudio transforms:\n",
        "  FrequencyMasking (freq_mask_param=6) and TimeMasking (time_mask_param=20), both applied during training.\n",
        "\n",
        "- **Notebook Execution**: Run cells sequentially from top to bottom. Requires PyTorch with CUDA, \n",
        "  torchaudio, wandb, and standard data science libraries (numpy, pandas, tqdm). \n",
        "  Data should be placed in the ROOT directory specified in the notebook.\n",
        "  Test-Time Augmentation (TTA) with 5 passes is used for final predictions.\n",
        "\"\"\"\n",
        "\n",
        "####################################\n",
        "#       Credentials (Optional)\n",
        "####################################\n",
        "\n",
        "# These are not required **IF** you have run the cells to declare these variables above.\n",
        "# If you would like to paste your credentials here again, feel free to:\n",
        "# OPTIONAL: Fill these out if you do not want to re-run previous cells to re-initialize these credential variables\n",
        "\n",
        "KAGGLE_USERNAME = \"xulunluo\"\n",
        "KAGGLE_API_KEY = \"2ce2c6e3c579210234c0853bb184a9fe\"\n",
        "\n",
        "if \"WANDB_API_KEY\" not in globals():\n",
        "  WANDB_API_KEY = None  # Fill in your wandb api key if needed\n",
        "\n",
        "\n",
        "####################################\n",
        "#             Wandb Logs\n",
        "####################################\n",
        "\n",
        "# Your wandb project url: https://wandb.ai/xulunl-carnegie-mellon-university/hw1p2\n",
        "\n",
        "WANDB_USERNAME_OR_TEAMNAME = \"xulunl-carnegie-mellon-university\"  # From your wandb output\n",
        "WANDB_PROJECT = \"hw1p2\"\n",
        "\n",
        "####################################\n",
        "#         Notebook & Files\n",
        "####################################\n",
        "\n",
        "# Notebook path - already correctly set\n",
        "NOTEBOOK_PATH = r\"C:\\Users\\xulunl\\Desktop\\Intro to DeepLearning\\HW1\\HW1P2\\HW1P2_Student_Starter_Notebook_TODO.ipynb\"\n",
        "\n",
        "# Model metadata JSON - update this path to where your generated file is located\n",
        "# Based on your notebook output, the file was saved as: model_metadata_2026-02-01_10-50.json\n",
        "MODEL_METADATA_JSON = r\"C:\\Users\\xulunl\\Desktop\\Intro to DeepLearning\\HW1\\HW1P2\\model_metadata_2026-02-05_14-11.json\"\n",
        "# NOTE: Update this path if your file is in a different location or has a different timestamp\n",
        "\n",
        "\n",
        "####################################\n",
        "#         Additional Files\n",
        "####################################\n",
        "\n",
        "ADDITIONAL_FILES = [\n",
        "    # Add paths to any additional files you want to include in your submission\n",
        "    # For example, if you have separate model.py files, add them here\n",
        "]\n",
        "\n",
        "####################################\n",
        "#         SLACK SUBMISSION\n",
        "####################################\n",
        "\n",
        "ENABLE_SLACK_SUBMISSION = False  # Set to True if submitting to Slack competition\n",
        "\n",
        "####################################\n",
        "#     Creating the Submission\n",
        "####################################\n",
        "\n",
        "SAFE_SUBMISSION = True  # Keep True to ensure all required files are present"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBuvtTWS7ev7"
      },
      "source": [
        "# Assignment Backend Submission Functions (DO NOT MODIFY, just run these cells)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "gsz5we7A7ev7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "######################################\n",
        "#       Assignment Configs\n",
        "######################################\n",
        "\n",
        "WANDB_METRIC = \"val_acc\"\n",
        "WANDB_DIRECTION = \"ascending\"\n",
        "WANDB_TOP_N = 10\n",
        "WANDB_OUTPUT_PKL = \"wandb_top_runs.pkl\"\n",
        "\n",
        "# Kaggle configuration\n",
        "COMPETITION_NAME = \"hw-1-p-2-spring-2026-student-competition\"\n",
        "SLACK_COMPETITION_NAME = \"hw-1-p-2-spring-2026-student-slack-submission\"\n",
        "FINAL_SUBMISSION_DATETIME = datetime.strptime(\"2026-02-06 23:59:59\", \"%Y-%m-%d %H:%M:%S\")\n",
        "SLACK_SUBMISSION_DATETIME = datetime.strptime(\"2026-02-13 23:59:59\", \"%Y-%m-%d %H:%M:%S\")\n",
        "GRADING_DIRECTION = \"ascending\"\n",
        "KAGGLE_OUTPUT_JSON = \"kaggle_data.json\"\n",
        "\n",
        "SUBMISSION_OUTPUT = \"HW1P2_final_submission.zip\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "e5EaHJ7r-LdW"
      },
      "outputs": [],
      "source": [
        "def strict_wandb_extract(obj):\n",
        "    \"\"\"\n",
        "    Robustly extracts data from WandB objects, handling strings,\n",
        "    broken wrappers, and standard dicts.\n",
        "    \"\"\"\n",
        "    # 1. If it's already a string, try to parse it as JSON.\n",
        "    # If not JSON, return the string as-is.\n",
        "    if isinstance(obj, str):\n",
        "        try:\n",
        "            return json.loads(obj)\n",
        "        except (ValueError, TypeError):\n",
        "            return obj\n",
        "\n",
        "    # 2. Workaround for the library crash:\n",
        "    # If it has the internal '_json_dict' attribute, use that directly\n",
        "    # to bypass the broken .items() method.\n",
        "    if hasattr(obj, '_json_dict'):\n",
        "        return strict_wandb_extract(obj._json_dict)\n",
        "\n",
        "    # 3. If it behaves like a normal dict, use .items()\n",
        "    if hasattr(obj, 'items'):\n",
        "        return dict(obj.items())\n",
        "\n",
        "    # 4. Fallback: Return as is\n",
        "    return obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Dfc1FzIk7ev7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "ACKNOWLEDGEMENT_MESSAGE = \"\"\"\n",
        "Submission of this file and assignment indicate the student's agreement to the following Aknowledgement requirements:\n",
        "Setting the ACNKOWLEDGED flag to True indicates full understanding and acceptance of the following:\n",
        "1. Slack days may ONLY be used on P2 FINAL (not checkpoint) submission. I.e. you may use slack days to submit final P2 kaggle scores (such as this one) later on the **SLACK KAGGLE COMPETITION** at the expense of your Slack days.\n",
        "2. The final autolab **code submission is due 48 hours after** the conclusion of the Kaggle Deadline (or, the same day as your final kaggle submission).\n",
        "3. Course staff will require your kaggle username here, and then will pull your official PRIVATE kaggle leaderboard score. This submission may result in slight variance in scores/code, but we will check for acceptable discrepancies. Any discrepancies related to modifying the submission code (at the bottom of the notebook) will result in an AIV.\n",
        "4. You are NOT allowed to use any code that will pre-load models (such as those from Hugging Face, etc.).\n",
        "   You MAY use models described by papers or articles, but you MUST implement them yourself through fundamental PyTorch operations (i.e. Linear, Conv2d, etc.).\n",
        "5. You are NOT allowed to use any external data/datasets at ANY point of this assignment.\n",
        "6. You may work with teammates to run ablations/experiments, BUT you must submit your OWN code and your OWN results.\n",
        "7. Failure to comply with the prior rules will be considered an Academic Integrity Violation (AIV).\n",
        "8. Late submissions MUST be submitted through the Slack Kaggle (see writeup for details). Any submissions made to the regular Kaggle after the original deadline will NOT be considered, no matter how many slack days remain for the student.\n",
        "\"\"\"\n",
        "def save_acknowledgment_file():\n",
        "    if ACKNOWLEDGED:\n",
        "        with open(\"acknowledgement.txt\", \"w\") as f:\n",
        "            f.write(ACKNOWLEDGEMENT_MESSAGE.strip())\n",
        "        print(\"Saved acknowledgement.txt\")\n",
        "        return True\n",
        "    else:\n",
        "        print(\"ERROR: Must set ACKNOWLEDGED = True.\")\n",
        "        return False\n",
        "# Saves README\n",
        "def save_readme(readme):\n",
        "    try:\n",
        "        with open(\"README.txt\", \"w\") as f:\n",
        "            f.write(readme.strip())\n",
        "\n",
        "        print(\"Saved README.txt\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Error occured while saving README.txt: {e}\")\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "# Saves wandb logs\n",
        "import wandb, json, pickle\n",
        "\n",
        "def save_top_wandb_runs():\n",
        "    wandb.login(key=WANDB_API_KEY)\n",
        "    if not ACKNOWLEDGED:\n",
        "        print(\"ERROR: Must set ACKNOWLEDGED = True.\")\n",
        "        return False\n",
        "\n",
        "    api = wandb.Api()\n",
        "    runs = api.runs(\n",
        "        f\"{WANDB_USERNAME_OR_TEAMNAME}/{WANDB_PROJECT}\",\n",
        "        order=f\"{'-' if WANDB_DIRECTION == 'descending' else ''}summary_metrics.{WANDB_METRIC}\"\n",
        "    )\n",
        "    selected_runs = runs[:min(WANDB_TOP_N, len(runs))]\n",
        "\n",
        "    if not selected_runs:\n",
        "        print(f\"ERROR: No runs found for {WANDB_USERNAME_OR_TEAMNAME}/{WANDB_PROJECT}. Please check that your wandb credentials (Wandb Username/Team Name, API Key, and Project Name) are correct.\")\n",
        "        return False\n",
        "\n",
        "    all_data = []\n",
        "    for run in selected_runs:\n",
        "        run_data = {\n",
        "            \"id\": run.id,\n",
        "            \"name\": run.name,\n",
        "            \"tags\": run.tags,\n",
        "            \"state\": run.state,\n",
        "            \"created_at\": str(run.created_at),\n",
        "            \"config\": json.loads(json.dumps(strict_wandb_extract(run.config), default=str)),\n",
        "            \"summary\": json.loads(json.dumps(strict_wandb_extract(run.summary), default=str))\n",
        "        }\n",
        "        try:\n",
        "            run_data[\"history\"] = run.history(samples=1000)\n",
        "        except Exception as e:\n",
        "            run_data[\"history\"] = f\"Failed to fetch history: {str(e)}\"\n",
        "        all_data.append(run_data)\n",
        "    with open(WANDB_OUTPUT_PKL, \"wb\") as f:\n",
        "        pickle.dump(all_data, f)\n",
        "\n",
        "    print(f\"OK: Exported {len(all_data)} WandB runs to {WANDB_OUTPUT_PKL}\")\n",
        "\n",
        "    return True\n",
        "# Saves kaggle information\n",
        "\n",
        "# Install dependencies silently (only if running on Colab)\n",
        "import sys\n",
        "\n",
        "from datetime import datetime\n",
        "import os, json, requests\n",
        "def kaggle_login(username, key):\n",
        "    os.makedirs(os.path.expanduser(\"~/.kaggle\"), exist_ok=True)\n",
        "    with open(os.path.expanduser(\"~/.kaggle/kaggle.json\"), \"w\") as f:\n",
        "        json.dump({\"username\": username, \"key\": key}, f)\n",
        "    os.chmod(os.path.expanduser(\"~/.kaggle/kaggle.json\"), 0o600)\n",
        "\n",
        "\n",
        "def get_active_submission_config():\n",
        "    if ENABLE_SLACK_SUBMISSION:\n",
        "        return SLACK_COMPETITION_NAME, SLACK_SUBMISSION_DATETIME\n",
        "    return COMPETITION_NAME, FINAL_SUBMISSION_DATETIME\n",
        "\n",
        "def kaggle_user_exists(usernagbme):\n",
        "    try:\n",
        "        return requests.get(f\"https://www.kaggle.com/{KAGGLE_USERNAME}\").status_code == 200\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Error while checking Kaggle user: {e}\")\n",
        "        return False\n",
        "\n",
        "DEFAULT_SCORE=0\n",
        "if GRADING_DIRECTION == \"ascending\":\n",
        "    DEFAULT_SCORE=0\n",
        "else:\n",
        "    DEFAULT_SCORE=1.0\n",
        "\n",
        "def get_best_kaggle_score(subs):\n",
        "    def extract_score(s):\n",
        "        return float(\n",
        "            (getattr(s, \"private_score\", None) or getattr(s, \"privateScore\", None)) or\n",
        "            (getattr(s, \"public_score\", None)  or getattr(s, \"publicScore\", None))  or\n",
        "            DEFAULT_SCORE\n",
        "        )\n",
        "    if not subs:\n",
        "        return None, None\n",
        "    best = max(subs, key=lambda s: extract_score(s) if GRADING_DIRECTION == \"ascending\" else -extract_score(s))\n",
        "    score_type = \"private\" if (getattr(best, \"private_score\", None) or getattr(best, \"privateScore\", None)) not in [None, \"\"] else \"public\"\n",
        "    return extract_score(best), score_type\n",
        "\n",
        "def save_kaggle_json(kaggle_username, kaggle_key):\n",
        "\n",
        "    kaggle_login(kaggle_username, kaggle_key)\n",
        "\n",
        "    from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "\n",
        "    if not ACKNOWLEDGED:\n",
        "        print(\"ERROR: Must set ACKNOWLEDGED = True.\")\n",
        "        return False\n",
        "\n",
        "    if not kaggle_user_exists(KAGGLE_USERNAME):\n",
        "        print(f\"ERROR: User '{KAGGLE_USERNAME}' not found.\")\n",
        "        return False\n",
        "\n",
        "    comp_name, deadline = get_active_submission_config()\n",
        "\n",
        "    api = KaggleApi()\n",
        "    api.authenticate()\n",
        "\n",
        "    # Get competition submissions\n",
        "    submissions = [s for s in api.competition_submissions(comp_name) if (getattr(s, \"submitted_by\", None) or getattr(s, \"submittedBy\", None)) == KAGGLE_USERNAME and getattr(s, \"date\") <= deadline]\n",
        "    if not submissions:\n",
        "        print(f\"ERROR: No valid submissions found for user [{KAGGLE_USERNAME}] for this competition [{comp_name}]. Slack flag set to [{ENABLE_SLACK_SUBMISSION}]\")\n",
        "        print(\"Please double check your Kaggle username and ensure you've submitted at least once.\")\n",
        "        return False\n",
        "\n",
        "    score, score_type = get_best_kaggle_score(submissions)\n",
        "    result = {\n",
        "        \"kaggle_username\": KAGGLE_USERNAME,\n",
        "        \"acknowledgement\": ACKNOWLEDGED,\n",
        "        \"submitted_slack\": ENABLE_SLACK_SUBMISSION,\n",
        "        \"competition_name\": comp_name,\n",
        "        \"deadline\": deadline.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "        \"raw_score\": score * 100.0,\n",
        "        \"score_type\": score_type,\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "    print(f\"OK: Projected score (excluding bonuses) saved as {KAGGLE_OUTPUT_JSON}\")\n",
        "    if score:\n",
        "        print(f\"Best score {score}.\")\n",
        "        with open(KAGGLE_OUTPUT_JSON, \"w\") as f:\n",
        "            json.dump(result, f, indent=2)\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import zipfile\n",
        "\n",
        "\n",
        "def create_submission_zip(additional_files, safe_flag):\n",
        "    if not \"ACKNOWLEDGED\" in globals() or not ACKNOWLEDGED:\n",
        "        print(\"ERROR: Make sure to RUN the Acknowledgement cell (at the top of the notebook). Also, must set ACKNOWLEDGED = True.\")\n",
        "        return\n",
        "\n",
        "    if (not save_acknowledgment_file()):\n",
        "        print(\"ERROR: Make sure to RUN the Acknowledgement cell (at the top of the notebook). Also, must set ACKNOWLEDGED = True.\")\n",
        "        return\n",
        "\n",
        "    if not \"ENABLE_SLACK_SUBMISSION\" in globals() or ENABLE_SLACK_SUBMISSION is None:\n",
        "        print(\"ERROR: \\\"ENABLE_SLACK_SUBMISSION\\\" variable is not defined. \\nTODO: Make sure to RUN the cell (A few cells up at the beginning of the submission section). \\nMake sure to set the ENABLE_SLACK_SUBMISSION checkbox if you're on colab, or set the parameter correctly set on other platforms \\n(if you are submitting through the SLACK submission).\")\n",
        "        return\n",
        "\n",
        "    if not \"README\" in globals() or not README:\n",
        "        print(\"ERROR: Make sure to RUN the README cell(above your credentials cell).\")\n",
        "        return\n",
        "\n",
        "    if (not save_readme(README)):\n",
        "        print(\"ERROR: Error while saving the README file. Make sure to complete and RUN the README cell(above your credentials cell).\")\n",
        "        return\n",
        "\n",
        "    if (not save_top_wandb_runs()):\n",
        "        return\n",
        "\n",
        "    if not \"KAGGLE_USERNAME\" in globals() or not \"KAGGLE_API_KEY\" in globals() or not KAGGLE_USERNAME or not KAGGLE_API_KEY:\n",
        "        print(\"ERROR: Make sure to set KAGGLE_USERNAME and KAGGLE_API_KEY for this code submission.\")\n",
        "        return\n",
        "\n",
        "    if (not save_kaggle_json(KAGGLE_USERNAME, KAGGLE_API_KEY)):\n",
        "        print(f\"ERROR: An error occured while retrieve kaggle information from username [{KAGGLE_USERNAME}] from competition [{get_active_submission_config()[0]}] with slack flag set to [{ENABLE_SLACK_SUBMISSION}]. Please check your kaggle username, key, and submission.\")\n",
        "        return\n",
        "\n",
        "    files_to_zip = [\n",
        "        \"acknowledgement.txt\",\n",
        "        \"README.txt\",\n",
        "        KAGGLE_OUTPUT_JSON,\n",
        "        WANDB_OUTPUT_PKL,\n",
        "        MODEL_METADATA_JSON,\n",
        "        NOTEBOOK_PATH,\n",
        "    ] + additional_files\n",
        "\n",
        "    custom_missing_files_messages = {\n",
        "        KAGGLE_OUTPUT_JSON: \"ERROR: Kaggle data retrieval was missing, please check your kaggle username, API Key, and that you have submitted to the correct competition.\"\n",
        "    }\n",
        "\n",
        "    missing_files = False\n",
        "\n",
        "    with zipfile.ZipFile(SUBMISSION_OUTPUT, \"w\") as zipf:\n",
        "        for file_path in files_to_zip:\n",
        "            if os.path.exists(file_path):\n",
        "                arcname = os.path.basename(file_path)  # flatten path\n",
        "                zipf.write(file_path, arcname=arcname)\n",
        "                print(f\"OK: Added {arcname}\")\n",
        "            else:\n",
        "                missing_files = True\n",
        "                print(f\"ERROR: Missing file: {file_path}\")\n",
        "\n",
        "    if missing_files:\n",
        "        if safe_flag:\n",
        "            print(\"ERROR: Missing files with safety flag set to True. Please upload any necessary files, ensure you have the correct paths and rerun all cells.\")\n",
        "            return\n",
        "        else:\n",
        "            print(\"WARNING: Missing files with safety flag set to False. Submission may be incomplete.\")\n",
        "\n",
        "    if \"google.colab\" in sys.modules and \"COLAB_GPU\" in os.environ:\n",
        "        from google.colab import files\n",
        "        files.download(SUBMISSION_OUTPUT)\n",
        "\n",
        "    print(\"Final submission saved as:\", SUBMISSION_OUTPUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cnTkp3D7ev8"
      },
      "source": [
        "# File Generation (TODO: Check file generation outputs for any errors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "yw-tdFiP7ev8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved acknowledgement.txt\n",
            "Saved README.txt\n",
            "OK: Exported 10 WandB runs to wandb_top_runs.pkl\n",
            "OK: Projected score (excluding bonuses) saved as kaggle_data.json\n",
            "Best score 0.8637.\n",
            "OK: Added acknowledgement.txt\n",
            "OK: Added README.txt\n",
            "OK: Added kaggle_data.json\n",
            "OK: Added wandb_top_runs.pkl\n",
            "ERROR: Missing file: C:\\Users\\xulunl\\Desktop\\Intro to DeepLearning\\HW1\\HW1P2\\model_metadata_2026-02-01_10-50.json\n",
            "OK: Added HW1P2_Student_Starter_Notebook_TODO.ipynb\n",
            "ERROR: Missing files with safety flag set to True. Please upload any necessary files, ensure you have the correct paths and rerun all cells.\n"
          ]
        }
      ],
      "source": [
        "create_submission_zip(ADDITIONAL_FILES, SAFE_SUBMISSION)\n",
        "\n",
        "#TODO: If the HW1P2_final_submission.zip file does not\n",
        "# automatically bring up a donwload pop-up\n",
        "# Then make sure to manually download the HW1P2_final_submission.zip file."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "idl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
